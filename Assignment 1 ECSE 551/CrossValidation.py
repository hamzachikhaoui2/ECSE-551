# -*- coding: utf-8 -*-
"""CrossValidation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qoxt-IIwKxe2EjZrIZ861-S1F0YiR4M3
"""

# ECSE 551 - Mini-Project 1
# Aymen Boustani 260916311, Hamza Chikhaoui 260912960

import numpy as np
import pandas as pd
from collections import Counter

class CrossValidation:

  # Initializes a CrossValidation instance
  def __init__(self, k):
    self.k = k # Number of folds

  # Defines the Accuracy function
  def Accueval(self, compare):
    TN = Counter(output[0] == 0 and output[1] == 0 for output in compare)[1]
    TP = Counter(output[0] == 1 and output[1] == 1 for output in compare)[1]
    FN = Counter(output[0] == 1 and output[1] == 0 for output in compare)[1]
    FP = Counter(output[0] == 0 and output[1] == 1 for output in compare)[1]
    return (TP + TN) / (TP + FP + FN + TN)

  # Defines the validate() function that computes accuracy for each fold among k folds
  def validate(self,model, X, Y, alpha, epsilon, lambda_val, regression_type, status, nested = False):
      folds = np.array_split(X, self.k)
      classes = np.array_split(Y, self.k)
      assert len(folds) == len(classes)
      l = len(folds)
      avg = 0
      accuracies = {}
      for i in range(l):
        index = l - i - 1
        X_test, Y_test= folds[index], classes[index]
        if not nested:
          X_train, Y_train = np.concatenate(folds[:index] + folds[index + 1:]), np.concatenate(classes[:index] + classes[index + 1:])
          model.fit(X_train, Y_train, alpha, epsilon, lambda_val,regression_type)
          predicted = model.predict(X_test)
          compare = np.stack((Y_test, predicted), axis = - 1)
          accuracy = self.Accueval(compare)
          avg += accuracy
          if status:
            print(f'Iteration {i + 1} of {self.k} - cross fold on the {model}: Accuracy obtained is {round(accuracy * 100,2)} %')
        if nested:
          avg_n = 0
          for j in range(l - 1):
            index_inner = l - j - 1
            X_test_inner, Y_test_inner= folds[index_inner], classes[index_inner]
            X_train, Y_train = np.concatenate(folds[:index_inner] + folds[index_inner + 1:]), np.concatenate(classes[:index_inner] + classes[index_inner + 1:])
            model.fit(X_train, Y_train, alpha, epsilon, lambda_val,regression_type)
            predicted = model.predict(X_test_inner)
            compare = np.stack((Y_test_inner, predicted), axis = - 1)
            u = self.Accueval(compare)
            avg_n += u
            if status:
              print(f'Iteration {j + 1} over the {i + 1} subfold of {self.k} - nested cross fold on the {model}: Accuracy obtained is {round(u * 100,2)} %')
          accuracies[index] = avg_n / (l - 1)
      if nested:
        best_k = max(accuracies, key = accuracies.get)
        X_test, Y_test= folds[best_k], classes[best_k]
        X_train, Y_train = np.concatenate(folds[:best_k] + folds[best_k + 1:]), np.concatenate(classes[:best_k] + classes[best_k + 1:])
        model.fit(X_train, Y_train, alpha, epsilon, lambda_val,regression_type)
        predicted = model.predict(X_test)
        compare = np.stack((Y_test, predicted), axis = - 1)
        avg = self.Accueval(compare)
        print(f'Best accuracy of {model} is : {round(avg * 100,2)} %')
      else:
        avg /= l
        print(f'Averrage accuracy of {model} is : {round(avg * 100,2)} %')
      return avg

test = np.array([[9, 4],
                 [0, 3],
                 [9, 0],
                 [9, 9]])
Counter(output[0] == 9 and output[1] == 0 for output in test)[1]

# @title Give me a name {display-mode: "form"}

# This code will be hidden when the notebook is loaded.

