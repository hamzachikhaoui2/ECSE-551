# -*- coding: utf-8 -*-
"""TextProcessor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oNvyhP4PFBMJ4eEnja6_V0499gX7BvU5
"""

# Commented out IPython magic to ensure Python compatibility.
#Download libraries
import numpy as np
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction import text
from nltk.corpus import stopwords
# %pip install nltk
import nltk
import string


nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')

from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import Normalizer
from nltk.stem import PorterStemmer
from nltk.stem.snowball import FrenchStemmer
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer, PorterStemmer

def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ,
                "N": wordnet.NOUN,
                "V": wordnet.VERB,
                "R": wordnet.ADV}
    return tag_dict.get(tag, wordnet.NOUN)

class LemmaTokenizer:
    def __init__(self):
        self.wnl = WordNetLemmatizer()

    def __call__(self, doc):
        return [self.wnl.lemmatize(t, pos="v") for t in word_tokenize(doc) if t.isalpha()]

class StemTokenizer:
    def __init__(self):
        self.wnl = PorterStemmer()

    def __call__(self, doc):
        return [self.wnl.stem(t) for t in word_tokenize(doc) if t.isalpha()]


class New_LemmaTokenizer:
     def __init__(self):
       self.wnl = WordNetLemmatizer()
     def __call__(self, doc):
       return [self.wnl.lemmatize(t,pos =get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]

class TextProcessor:
    def __init__(self,removing_punct,stop_words_removal, tf_idf, token, normalization, features = 3000, ngrams = (1, 1)):
        self.normalization = normalization
        self.removing_punct = removing_punct
        self.token = token
        self.tf_idf = tf_idf
        self.stop_words_removal = stop_words_removal
        self.vectorizer = 0
        self.features = features
        self.ngrams = ngrams

    def tokenize_text(self, text):
        return self.token(text)


    def trainX (self, text):
      french_stop_words = set(stopwords.words('french'))
      english_stop_words = set(stopwords.words('english'))
      punctuation = set(string.punctuation)

      #Punctuation
      if self.removing_punct:
        combined_stop_words = list(french_stop_words.union(english_stop_words).union(punctuation))
      else:
        combined_stop_words = list(french_stop_words.union(english_stop_words))


      #StopWords
      if self.stop_words_removal:
        stopWords = combined_stop_words
      else:
        stopWords = None



      if self.tf_idf == True :
          vectorizer = TfidfVectorizer(
          max_features = self.features,
          binary = True,  # Use binary instead of term frequency
          tokenizer = self.token, #Lemma or Stemming
          stop_words = stopWords,
          ngram_range = self.ngrams
         )

      else:
          vectorizer = CountVectorizer(
          max_features = self.features,
          binary = True,  # Use binary instead of term frequency
          tokenizer = self.token,#Lemma or Stemming
          stop_words = stopWords,
          ngram_range = self.ngrams
          )

      self.vectorizer = vectorizer
      Xtrain = self.vectorizer.fit_transform(text.to_numpy().T[0])

#normalization
      if self.normalization:
          normalizer_train = Normalizer().fit(X=Xtrain)
          Xtrain_train_normalized = normalizer_train.transform(Xtrain)
          return Xtrain_train_normalized.toarray()
      else:
        return Xtrain.toarray()




    def test_corpus(self, test_corpus):
      Xtrain_test = self.vectorizer.transform(test_corpus)
      return Xtrain_test.toarray()

