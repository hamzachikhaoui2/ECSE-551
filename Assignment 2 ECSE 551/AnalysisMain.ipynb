{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhal2RI9PUqn"
   },
   "outputs": [],
   "source": [
    "# ECSE 551 - MP2  \n",
    "# Aymen Boustani 260916311 Hamza Chikhaoui 260912960\n",
    "\n",
    "# We start by installing the some of the packages that are not by default on Google Colab\n",
    "\n",
    "%pip install nltk\n",
    "%pip install langdetect\n",
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfAuvrzwDSoT",
    "outputId": "97abe31b-d119-44cf-de9d-1b8a9dc73b6d"
   },
   "outputs": [],
   "source": [
    "# More specific packages to download...\n",
    "\n",
    "!python3 -m spacy download en_core_web_sm\n",
    "!python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the mandatory modules...\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import importlib\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from langdetect import detect\n",
    "from naivebayes import NaiveBayes\n",
    "from textprocessor import TextProcessor\n",
    "from itertools import product\n",
    "from crossvalidationmp2 import CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CjLIvQuZMIz",
    "outputId": "5e39739c-f2fe-4dfe-e1b5-217a57222cd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last packages to download...\n",
    "\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "umEFtOYXL6d4"
   },
   "outputs": [],
   "source": [
    "# We start by importing the CSV files as Pandas DataFrame and shuffle them using the sample() function\n",
    "\n",
    "train_corpus = pd.read_csv('train.csv', encoding = 'cp1252' ).sample(frac = 1)\n",
    "test_corpus = pd.read_csv('test.csv', encoding = 'cp1252' ).sample(frac = 1)\n",
    "max_features = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "gSel0v-8MRPy",
    "outputId": "e49812e2-6daf-449c-9795-4b8ea7e101f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td># Upvote/Downvote reminder\\n\\nLike this image ...</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Il y'a quelques années, avenue Charles de Gaul...</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>We tried to see the exhibits, except many had ...</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>What is the speed limit there?  That street lo...</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Le 11e, limite 12e (vers Faidherbe-Reuilly). J...</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>A lot of established massage therapists don't ...</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Probablement un avion d'Aero Sotravia qui fait...</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Since paying the membership fee doesn't guaran...</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Its the reasonable doubt standard: The judge h...</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>I watched a creep take a photo on his phone of...</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body subreddit\n",
       "353  # Upvote/Downvote reminder\\n\\nLike this image ...    London\n",
       "462  Il y'a quelques années, avenue Charles de Gaul...     Paris\n",
       "65   We tried to see the exhibits, except many had ...   Toronto\n",
       "142  What is the speed limit there?  That street lo...   Toronto\n",
       "467  Le 11e, limite 12e (vers Faidherbe-Reuilly). J...     Paris\n",
       "..                                                 ...       ...\n",
       "593  A lot of established massage therapists don't ...  Montreal\n",
       "387  Probablement un avion d'Aero Sotravia qui fait...     Paris\n",
       "568  Since paying the membership fee doesn't guaran...  Montreal\n",
       "656  Its the reasonable doubt standard: The judge h...  Montreal\n",
       "301  I watched a creep take a photo on his phone of...    London\n",
       "\n",
       "[719 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of the training corpus\n",
    "\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "j8SJSQboLJjE",
    "outputId": "97b6a032-5726-4a6e-c9dc-3c54d331a866"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td># Upvote/Downvote reminder\\n\\nLike this image ...</td>\n",
       "      <td>London</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Il y'a quelques années, avenue Charles de Gaul...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>We tried to see the exhibits, except many had ...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>What is the speed limit there?  That street lo...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Le 11e, limite 12e (vers Faidherbe-Reuilly). J...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>A lot of established massage therapists don't ...</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Probablement un avion d'Aero Sotravia qui fait...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Since paying the membership fee doesn't guaran...</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Its the reasonable doubt standard: The judge h...</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>I watched a creep take a photo on his phone of...</td>\n",
       "      <td>London</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>719 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body subreddit  labels\n",
       "353  # Upvote/Downvote reminder\\n\\nLike this image ...    London       0\n",
       "462  Il y'a quelques années, avenue Charles de Gaul...     Paris       1\n",
       "65   We tried to see the exhibits, except many had ...   Toronto       2\n",
       "142  What is the speed limit there?  That street lo...   Toronto       2\n",
       "467  Le 11e, limite 12e (vers Faidherbe-Reuilly). J...     Paris       1\n",
       "..                                                 ...       ...     ...\n",
       "593  A lot of established massage therapists don't ...  Montreal       3\n",
       "387  Probablement un avion d'Aero Sotravia qui fait...     Paris       1\n",
       "568  Since paying the membership fee doesn't guaran...  Montreal       3\n",
       "656  Its the reasonable doubt standard: The judge h...  Montreal       3\n",
       "301  I watched a creep take a photo on his phone of...    London       0\n",
       "\n",
       "[719 rows x 3 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializes a column with numbers corresponding to each subreddit\n",
    "\n",
    "train_corpus['labels'], unique_categories = pd.factorize(train_corpus['subreddit'])\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCBw95Kx25kL",
    "outputId": "6419376a-f61b-429a-caca-6bc116362e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['London', 'Paris', 'Toronto', 'Montreal'], dtype='object')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "bGD6sJdeXzqt"
   },
   "outputs": [],
   "source": [
    "# Initializes the Tokenizers that will be used\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.nlp_en = spacy.load('en_core_web_sm')\n",
    "        self.nlp_fr = spacy.load('fr_core_news_sm')\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return self.lemmatize(doc)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Lemma Tokenizer\"\n",
    "\n",
    "    def detect_language(self, text):\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            return lang\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    def lemmatize(self, text):\n",
    "        lang = self.detect_language(text)\n",
    "        if lang == 'fr':\n",
    "            return [token.lemma_ for token in self.nlp_fr(text) if token.text.isalpha()]\n",
    "        else:\n",
    "            return [self.wnl.lemmatize(t, pos=\"v\") for t in word_tokenize(text) if t.isalpha()]\n",
    "\n",
    "class TFIDFVectorizer:\n",
    "    def __init__(self, documents):\n",
    "        self.documents = documents\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(documents)\n",
    "\n",
    "    def __call__(self, query):\n",
    "        query_tfidf = self.vectorizer.transform([query])\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        tfidf_scores = []\n",
    "        for col in query_tfidf.nonzero()[1]:\n",
    "            term = feature_names[col]\n",
    "            score = query_tfidf[0, col]\n",
    "            tfidf_scores.append((term, score))\n",
    "        tfidf_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return tfidf_scores\n",
    "\n",
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl_en = PorterStemmer()\n",
    "        self.wnl_fr = SnowballStemmer('french')\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return self.stem(doc)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Stemming Tokenizer\"\n",
    "\n",
    "    def detect_language(self, text):\n",
    "        try:\n",
    "            lang = detect(text)\n",
    "            return lang\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "    def stem(self, text):\n",
    "        lang = self.detect_language(text)\n",
    "        if lang == 'fr':\n",
    "            return [self.wnl_fr.stem(t) for t in word_tokenize(text) if t.isalpha()]\n",
    "        else:\n",
    "            return [self.wnl_en.stem(t) for t in word_tokenize(text) if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H133IWcUMx8Y",
    "outputId": "6bbd2458-b1ee-47a8-84e5-29f429851e16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 2, 1, 3, 1, 0, 2, 3, 3, 1, 0, 0, 0, 2, 3, 2, 3, 3, 0, 0,\n",
       "       3, 1, 2, 1, 0, 2, 1, 3, 1, 2, 3, 1, 3, 3, 3, 3, 2, 0, 2, 3, 2, 2,\n",
       "       0, 2, 3, 0, 1, 2, 0, 1, 0, 2, 0, 3, 0, 2, 1, 0, 1, 3, 2, 0, 2, 3,\n",
       "       0, 0, 0, 0, 2, 0, 1, 1, 3, 3, 3, 0, 1, 3, 0, 0, 3, 0, 1, 0, 0, 0,\n",
       "       3, 2, 0, 2, 1, 2, 2, 1, 2, 0, 3, 2, 1, 0, 2, 3, 0, 3, 0, 2, 1, 2,\n",
       "       1, 1, 1, 2, 0, 2, 3, 3, 3, 2, 0, 2, 0, 2, 0, 2, 3, 1, 2, 2, 3, 0,\n",
       "       3, 3, 2, 0, 0, 2, 1, 1, 1, 2, 2, 0, 1, 3, 0, 1, 3, 3, 3, 0, 1, 0,\n",
       "       0, 3, 0, 2, 3, 0, 1, 0, 0, 2, 1, 1, 1, 1, 0, 3, 0, 1, 1, 3, 2, 3,\n",
       "       0, 3, 3, 3, 1, 2, 2, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 1, 2, 2, 3, 2,\n",
       "       0, 2, 2, 1, 3, 3, 1, 0, 1, 2, 0, 2, 0, 3, 2, 1, 1, 2, 2, 1, 1, 0,\n",
       "       1, 0, 2, 3, 2, 3, 1, 2, 1, 3, 3, 0, 1, 0, 3, 1, 3, 0, 2, 2, 0, 1,\n",
       "       0, 2, 1, 0, 1, 0, 0, 2, 2, 2, 3, 2, 2, 1, 2, 0, 0, 2, 2, 1, 3, 3,\n",
       "       3, 0, 2, 0, 2, 2, 1, 3, 3, 1, 2, 2, 2, 0, 0, 3, 3, 0, 2, 1, 3, 1,\n",
       "       3, 1, 2, 0, 1, 1, 2, 0, 1, 2, 2, 3, 0, 1, 1, 2, 2, 0, 0, 1, 2, 1,\n",
       "       0, 0, 2, 2, 1, 3, 3, 0, 3, 1, 1, 1, 3, 2, 1, 3, 1, 2, 1, 1, 0, 2,\n",
       "       1, 2, 0, 2, 0, 1, 3, 3, 1, 0, 2, 0, 1, 3, 1, 1, 0, 3, 2, 2, 3, 2,\n",
       "       1, 0, 1, 2, 3, 1, 3, 0, 2, 3, 1, 1, 3, 0, 0, 1, 0, 0, 2, 3, 1, 0,\n",
       "       3, 2, 1, 0, 1, 2, 2, 2, 0, 2, 1, 1, 2, 2, 3, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 2, 3, 0, 1, 1, 3, 0, 2, 2, 3, 3, 0, 2, 0, 0, 0, 1, 3, 2, 0, 3,\n",
       "       0, 1, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 3, 1, 3, 1, 3, 3, 2, 1, 1, 3,\n",
       "       0, 2, 0, 1, 3, 0, 2, 3, 1, 0, 3, 1, 0, 0, 2, 1, 2, 3, 3, 2, 0, 0,\n",
       "       2, 3, 1, 1, 3, 0, 3, 2, 0, 3, 0, 1, 0, 2, 2, 2, 1, 0, 1, 1, 2, 3,\n",
       "       3, 2, 2, 0, 3, 1, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 3, 3,\n",
       "       2, 1, 1, 3, 0, 0, 3, 2, 1, 0, 1, 2, 3, 2, 3, 2, 0, 2, 3, 3, 3, 0,\n",
       "       3, 1, 0, 0, 1, 2, 1, 2, 0, 1, 3, 0, 1, 1, 3, 2, 3, 2, 1, 0, 1, 3,\n",
       "       2, 3, 0, 0, 0, 1, 2, 3, 3, 2, 3, 3, 1, 0, 1, 1, 3, 2, 0, 3, 3, 2,\n",
       "       2, 1, 3, 1, 1, 3, 2, 2, 2, 1, 3, 3, 2, 2, 2, 2, 3, 3, 3, 2, 0, 3,\n",
       "       0, 0, 1, 2, 1, 3, 3, 1, 3, 3, 0, 3, 2, 2, 1, 3, 3, 2, 2, 0, 2, 3,\n",
       "       1, 0, 2, 0, 1, 0, 0, 0, 0, 3, 3, 2, 0, 1, 1, 0, 2, 3, 2, 0, 2, 0,\n",
       "       3, 2, 1, 1, 0, 1, 2, 3, 0, 3, 1, 2, 3, 2, 0, 0, 1, 3, 3, 3, 1, 1,\n",
       "       3, 3, 0, 3, 3, 3, 3, 2, 3, 0, 0, 3, 2, 3, 3, 0, 1, 2, 3, 3, 1, 1,\n",
       "       0, 2, 2, 2, 3, 3, 0, 0, 1, 0, 3, 3, 3, 0, 1, 3, 1, 1, 0, 1, 0, 3,\n",
       "       1, 3, 2, 3, 3, 1, 1, 2, 0, 1, 3, 1, 3, 3, 0])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializes the Y_train array contained the actual labels\n",
    "\n",
    "Y_train = train_corpus['labels'].to_numpy()\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 869
    },
    "id": "Q0UTakKK4oyG",
    "outputId": "c3b6a2a5-958a-438c-e6a3-cdc391ed9756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 1 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 1 was 11.058075904846191 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 2 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 2 was 16.953678846359253 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 3 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 3 was 13.377267122268677 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 4 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 4 was 17.122214317321777 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 5 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 5 was 22.114546060562134 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 6 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 6 was 19.098212003707886 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 7 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 7 was 23.45460605621338 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 8 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 8 was 27.63563108444214 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 9 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 9 was 24.902865886688232 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 10 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 10 was 28.484307765960693 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 11 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 11 was 33.28011775016785 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 12 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 12 was 30.516355991363525 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 13 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 13 was 34.46783208847046 s long\n",
      "Averrage accuracy of Naive Bayes is : 23.08 %\n",
      "Iteration 14 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 14 was 39.96187686920166 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 15 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 15 was 36.286482095718384 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 16 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 16 was 11.213207006454468 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 17 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 17 was 16.275372982025146 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 18 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 18 was 13.708764791488647 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 19 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 19 was 16.89222502708435 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 20 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 20 was 21.607281923294067 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 21 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 21 was 19.05312991142273 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 22 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 22 was 22.489288091659546 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 23 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 23 was 26.927618741989136 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 24 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 24 was 24.293954133987427 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 25 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 25 was 27.95147705078125 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 26 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 26 was 32.51680302619934 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 27 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 27 was 29.993601083755493 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 28 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 28 was 33.62725210189819 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 29 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 29 was 37.90461802482605 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 30 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 30 was 35.449613094329834 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 31 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 31 was 11.047914028167725 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 32 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 32 was 15.877992868423462 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 33 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 33 was 13.38994812965393 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 34 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 34 was 16.481623888015747 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 35 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 35 was 21.300018072128296 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 36 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 36 was 18.91614580154419 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 37 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 37 was 22.095561027526855 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 38 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 38 was 26.846524715423584 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 39 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 39 was 24.350250959396362 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 40 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 40 was 27.650536060333252 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 41 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 41 was 32.34301495552063 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 42 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 42 was 29.919615983963013 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 43 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 43 was 32.9925639629364 s long\n",
      "Averrage accuracy of Naive Bayes is : 23.08 %\n",
      "Iteration 44 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 44 was 37.92826008796692 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 45 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 45 was 35.369080781936646 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 46 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 46 was 11.03529405593872 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 47 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 47 was 15.863667011260986 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 48 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 48 was 13.362902164459229 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 49 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 49 was 16.482542991638184 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 50 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 50 was 21.33761191368103 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 51 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 51 was 18.89499592781067 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 52 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 52 was 22.342588901519775 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 53 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 53 was 26.99158501625061 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 54 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 54 was 24.33586096763611 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 55 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 55 was 27.673007249832153 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 56 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 56 was 32.4203839302063 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 57 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 57 was 30.016949892044067 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 58 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 58 was 32.9896080493927 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 59 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 59 was 37.90211200714111 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 60 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 60 was 35.435137033462524 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 61 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 61 was 11.14883279800415 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 62 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 62 was 15.941477060317993 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 63 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 63 was 13.351595878601074 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 64 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 64 was 16.754738330841064 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 65 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 65 was 21.47349977493286 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 66 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 66 was 18.914937257766724 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 67 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 67 was 22.350688934326172 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.75 %\n",
      "Iteration 68 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 68 was 26.97076416015625 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 69 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 69 was 24.427720069885254 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 70 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 70 was 27.962336778640747 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 71 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 71 was 32.50320816040039 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 72 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 72 was 29.875090837478638 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 73 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 73 was 33.49714994430542 s long\n",
      "Averrage accuracy of Naive Bayes is : 23.08 %\n",
      "Iteration 74 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 74 was 37.83078622817993 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 75 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 75 was 35.39452910423279 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 76 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 76 was 11.176294803619385 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 77 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 77 was 15.925594091415405 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 78 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 78 was 13.357311010360718 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.62 %\n",
      "Iteration 79 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 79 was 16.725531101226807 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 80 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 80 was 21.364750862121582 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 81 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 81 was 18.899451971054077 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 82 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 82 was 22.290974855422974 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 83 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 83 was 26.991153240203857 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.2 %\n",
      "Iteration 84 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 84 was 24.533719778060913 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.33 %\n",
      "Iteration 85 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 85 was 28.054877758026123 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 86 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 86 was 32.64498710632324 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 87 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 87 was 30.035155057907104 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 88 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 88 was 34.142138957977295 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.03 %\n",
      "Iteration 89 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 89 was 39.96451020240784 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.47 %\n",
      "Iteration 90 out of 120 with TF - IDF = False | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 90 was 35.70448899269104 s long\n",
      "Averrage accuracy of Naive Bayes is : 58.27 %\n",
      "Iteration 91 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 91 was 11.221439838409424 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 57.02 %\n",
      "Iteration 92 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 92 was 16.04846692085266 s long\n",
      "Averrage accuracy of Naive Bayes is : 59.94 %\n",
      "Iteration 93 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 93 was 13.516576766967773 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.49 %\n",
      "Iteration 94 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 94 was 16.60935401916504 s long\n",
      "Averrage accuracy of Naive Bayes is : 59.94 %\n",
      "Iteration 95 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 95 was 21.502678871154785 s long\n",
      "Averrage accuracy of Naive Bayes is : 59.8 %\n",
      "Iteration 96 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 96 was 18.943104028701782 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.17 %\n",
      "Iteration 97 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 97 was 22.061283111572266 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 61.47 %\n",
      "Iteration 98 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 98 was 27.08625316619873 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.92 %\n",
      "Iteration 99 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 99 was 24.741830110549927 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.42 %\n",
      "Iteration 100 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 100 was 27.81588101387024 s long\n",
      "Averrage accuracy of Naive Bayes is : 61.47 %\n",
      "Iteration 101 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 101 was 32.81072115898132 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.92 %\n",
      "Iteration 102 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 102 was 30.22864079475403 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.15 %\n",
      "Iteration 103 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 103 was 33.24133920669556 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 62.31 %\n",
      "Iteration 104 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 104 was 39.330583810806274 s long\n",
      "Averrage accuracy of Naive Bayes is : 61.34 %\n",
      "Iteration 105 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 105 was 36.44057822227478 s long\n",
      "Averrage accuracy of Naive Bayes is : 46.44 %\n",
      "Iteration 106 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 106 was 11.732973098754883 s long\n",
      "Averrage accuracy of Naive Bayes is : 46.59 %\n",
      "Iteration 107 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 107 was 17.206349849700928 s long\n",
      "Averrage accuracy of Naive Bayes is : 47.84 %\n",
      "Iteration 108 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 108 was 14.276840925216675 s long\n",
      "Averrage accuracy of Naive Bayes is : 40.05 %\n",
      "Iteration 109 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 109 was 17.100021839141846 s long\n",
      "Averrage accuracy of Naive Bayes is : 40.47 %\n",
      "Iteration 110 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 110 was 22.032677173614502 s long\n",
      "Averrage accuracy of Naive Bayes is : 37.69 %\n",
      "Iteration 111 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 111 was 19.19107675552368 s long\n",
      "Averrage accuracy of Naive Bayes is : 33.93 %\n",
      "Iteration 112 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 112 was 22.408071279525757 s long\n",
      "Averrage accuracy of Naive Bayes is : 34.36 %\n",
      "Iteration 113 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 113 was 27.63295602798462 s long\n",
      "Averrage accuracy of Naive Bayes is : 34.5 %\n",
      "Iteration 114 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 114 was 24.403106689453125 s long\n",
      "Averrage accuracy of Naive Bayes is : 31.15 %\n",
      "Iteration 115 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 115 was 27.546061038970947 s long\n",
      "Averrage accuracy of Naive Bayes is : 32.0 %\n",
      "Iteration 116 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 116 was 32.494438886642456 s long\n",
      "Averrage accuracy of Naive Bayes is : 32.68 %\n",
      "Iteration 117 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 117 was 30.049307107925415 s long\n",
      "Averrage accuracy of Naive Bayes is : 29.48 %\n",
      "Iteration 118 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 118 was 32.98555326461792 s long\n",
      "Averrage accuracy of Naive Bayes is : 30.46 %\n",
      "Iteration 119 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 119 was 37.864585876464844 s long\n",
      "Averrage accuracy of Naive Bayes is : 30.6 %\n",
      "Iteration 120 out of 120 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 120 was 35.48912310600281 s long\n"
     ]
    }
   ],
   "source": [
    "# 10 folds Cross Validation on BNB:\n",
    "tfidf = normalization = smooth = [True, False]\n",
    "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
    "accuracies, count, execution = {}, 1, {}\n",
    "for t in tfidf:\n",
    "    for normal in normalization:\n",
    "        for s in smooth:\n",
    "            for n in features:\n",
    "                for token in tokens:\n",
    "                    start = time.time()\n",
    "                    label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}'\n",
    "                    processor = TextProcessor(True, True, t, token, normal, n)\n",
    "                    X = processor.trainX(train_corpus)\n",
    "                    model, validation = NaiveBayes(s), CrossValidation(10)\n",
    "                    accuracies[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "                    end = time.time()\n",
    "                    step = end - start\n",
    "                    execution[label] = step\n",
    "                    print(f'Iteration {count} out of 120 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
    "                    print(f'Iteration {count} was {step} s long')\n",
    "                    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = max(accuracies, key = accuracies.get)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.81588101387024"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "features = np.linspace(1000, 3000, 5, dtype = int)\n",
    "for feature in features:\n",
    "    trick = [key for key in execution.keys() if f'Number of features = {feature}' in key]\n",
    "    results.append(np.mean([execution[key] for key in trick]))\n",
    "plt.grid()\n",
    "plt.plot(features, results, color = 'r')\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Runtime execution (s)')\n",
    "plt.title('Runtime execution vs number of features for BNB optimization')\n",
    "plt.savefig('bnb.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 63.42 %\n",
      "Iteration 1 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 1 was 27.656095027923584 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 61.47 %\n",
      "Iteration 2 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 2 was 35.36267900466919 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 60.92 %\n",
      "Iteration 3 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 3 was 34.283665895462036 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.15 %\n",
      "Iteration 4 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2625 | Tokenizer = None\n",
      "Iteration 4 was 29.12404990196228 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.44 %\n",
      "Iteration 5 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2625 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 5 was 34.52461576461792 s long\n",
      "Averrage accuracy of Naive Bayes is : 61.34 %\n",
      "Iteration 6 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2625 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 6 was 32.43931293487549 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.87 %\n",
      "Iteration 7 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2750 | Tokenizer = None\n",
      "Iteration 7 was 32.041542768478394 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 62.03 %\n",
      "Iteration 8 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2750 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 8 was 36.18333077430725 s long\n",
      "Averrage accuracy of Naive Bayes is : 61.06 %\n",
      "Iteration 9 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2750 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 9 was 32.996607065200806 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.43 %\n",
      "Iteration 10 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2875 | Tokenizer = None\n",
      "Iteration 10 was 32.06395506858826 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 62.72 %\n",
      "Iteration 11 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2875 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 11 was 37.193110704422 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 61.06 %\n",
      "Iteration 12 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 2875 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 12 was 35.23127007484436 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.15 %\n",
      "Iteration 13 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 13 was 33.65102410316467 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 62.31 %\n",
      "Iteration 14 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 14 was 38.110538959503174 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 61.34 %\n",
      "Iteration 15 out of 15 with TF - IDF = False | Normalization = False | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 15 was 35.680952072143555 s long\n"
     ]
    }
   ],
   "source": [
    "# 10 folds Cross Validation with the hyperparameters yielding out the best values:\n",
    "tfidf = normal = False\n",
    "smooth = True\n",
    "features, tokens = np.linspace(2500, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
    "accuracies_, count, execution_ = {}, 1, {}\n",
    "for n in features:\n",
    "    for token in tokens:\n",
    "        start = time.time()\n",
    "        label = f'TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {n} | Tokenizer = {token}'\n",
    "        processor = TextProcessor(True, True, tfidf, token, normal, n)\n",
    "        X = processor.trainX(train_corpus)\n",
    "        model, validation = NaiveBayes(smooth), CrossValidation(10)\n",
    "        accuracies_[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "        end = time.time()\n",
    "        step = end - start\n",
    "        execution_[label] = step\n",
    "        print(f'Iteration {count} out of 15 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
    "        print(f'Iteration {count} was {step} s long')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2875 | Tokenizer = None'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = max(accuracies_, key = accuracies_.get)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLypGNEuyE9q"
   },
   "source": [
    "# Compare results with Decision tree classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "657SGoqlyIWw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_features=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_features=3000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_features=3000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calls the SkLearn Decisio Tree Classifier\n",
    "# This part of the code was to familiarize ourselves with the classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "classes = unique_categories\n",
    "classifier = DecisionTreeClassifier(max_features = max_features)\n",
    "classifier.fit(X_train_vec, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 3, 2, 3, 0, 2, 0, 1, 1, 1, 3, 3, 0, 2, 0, 2, 1, 1, 2, 2,\n",
       "       0, 2, 2, 2, 3, 1, 3, 2, 0, 0, 0, 3, 2, 0, 1, 2, 0, 0, 3, 3, 3, 1,\n",
       "       3, 3, 3, 2, 2, 3, 2, 1, 3, 1, 2, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2, 3,\n",
       "       3, 1, 0, 1, 2, 2, 3, 1, 3, 2, 2, 1, 2, 2, 0, 3, 0, 2, 2, 0, 1, 1,\n",
       "       2, 0, 2, 0, 3, 1, 0, 2, 2, 2, 0, 1, 1, 3, 0, 0, 3, 2, 2, 2, 3, 2,\n",
       "       0, 0, 1, 3, 2, 0, 2, 0, 0, 0, 3, 3, 3, 0, 3, 1, 1, 2, 2, 1, 3, 1,\n",
       "       2, 0, 0, 3, 2, 2, 3, 0, 3, 0, 3, 0, 2, 0, 3, 2, 3, 1, 1, 3, 1, 0,\n",
       "       2, 0, 1, 3, 1, 3, 3, 0, 0, 1, 0, 2, 2, 0, 0, 2, 3, 3, 3, 2, 3, 1,\n",
       "       0, 1, 3, 2, 0, 3, 0, 0, 3, 2, 2, 2, 1, 3, 3, 0, 0, 1, 2, 1, 0, 2,\n",
       "       2, 0, 0, 2, 2, 2, 0, 0, 1, 3, 0, 3, 1, 3, 1, 3, 0, 2, 2, 2, 3, 0,\n",
       "       0, 3, 1, 2, 1, 2, 0, 3, 1, 2, 2, 3, 3, 3, 1, 1, 0, 2, 0, 0, 3, 3,\n",
       "       3, 0, 0, 2, 3, 3, 3, 3, 1, 3, 1, 2, 2, 3, 3, 2, 2, 0, 2, 3, 1, 1,\n",
       "       1, 0, 1, 2, 3, 3, 0, 0, 0, 0, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTpred = classifier.predict(X_test)\n",
    "DTpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Going to pick up our Turkey from the butcher then will brine it overnight before cooking for guests tomorrow. Food shopping, trip to LCBO for some wine, then prep prep prep, a walk to get the lead out, and then a light dinner before bed.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'London'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories[DTpred[90]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1000) is : 31.58 %\n",
      "Iteration 1 out of 120 with Number of features = 1000 | Maximum depth = 2\n",
      "Iteration 1 was 0.12614107131958008 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1000) is : 45.48 %\n",
      "Iteration 2 out of 120 with Number of features = 1000 | Maximum depth = 4\n",
      "Iteration 2 was 0.10445022583007812 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1000) is : 46.03 %\n",
      "Iteration 3 out of 120 with Number of features = 1000 | Maximum depth = 6\n",
      "Iteration 3 was 0.1342921257019043 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1000) is : 45.63 %\n",
      "Iteration 4 out of 120 with Number of features = 1000 | Maximum depth = 8\n",
      "Iteration 4 was 0.14693593978881836 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1000) is : 46.87 %\n",
      "Iteration 5 out of 120 with Number of features = 1000 | Maximum depth = 10\n",
      "Iteration 5 was 0.16184306144714355 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1000) is : 52.01 %\n",
      "Iteration 6 out of 120 with Number of features = 1000 | Maximum depth = 12\n",
      "Iteration 6 was 0.1817481517791748 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1500) is : 36.3 %\n",
      "Iteration 7 out of 120 with Number of features = 1500 | Maximum depth = 2\n",
      "Iteration 7 was 0.10411596298217773 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1500) is : 45.9 %\n",
      "Iteration 8 out of 120 with Number of features = 1500 | Maximum depth = 4\n",
      "Iteration 8 was 0.13140487670898438 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1500) is : 47.57 %\n",
      "Iteration 9 out of 120 with Number of features = 1500 | Maximum depth = 6\n",
      "Iteration 9 was 0.1574993133544922 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1500) is : 46.74 %\n",
      "Iteration 10 out of 120 with Number of features = 1500 | Maximum depth = 8\n",
      "Iteration 10 was 0.1875629425048828 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1500) is : 48.26 %\n",
      "Iteration 11 out of 120 with Number of features = 1500 | Maximum depth = 10\n",
      "Iteration 11 was 0.21663284301757812 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1500) is : 51.46 %\n",
      "Iteration 12 out of 120 with Number of features = 1500 | Maximum depth = 12\n",
      "Iteration 12 was 0.24331402778625488 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2000) is : 36.58 %\n",
      "Iteration 13 out of 120 with Number of features = 2000 | Maximum depth = 2\n",
      "Iteration 13 was 0.09882688522338867 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2000) is : 45.21 %\n",
      "Iteration 14 out of 120 with Number of features = 2000 | Maximum depth = 4\n",
      "Iteration 14 was 0.15336012840270996 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2000) is : 43.82 %\n",
      "Iteration 15 out of 120 with Number of features = 2000 | Maximum depth = 6\n",
      "Iteration 15 was 0.19418978691101074 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2000) is : 46.6 %\n",
      "Iteration 16 out of 120 with Number of features = 2000 | Maximum depth = 8\n",
      "Iteration 16 was 0.23305487632751465 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2000) is : 49.09 %\n",
      "Iteration 17 out of 120 with Number of features = 2000 | Maximum depth = 10\n",
      "Iteration 17 was 0.27468204498291016 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2000) is : 51.6 %\n",
      "Iteration 18 out of 120 with Number of features = 2000 | Maximum depth = 12\n",
      "Iteration 18 was 0.29963111877441406 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2500) is : 37.41 %\n",
      "Iteration 19 out of 120 with Number of features = 2500 | Maximum depth = 2\n",
      "Iteration 19 was 0.12134122848510742 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2500) is : 45.48 %\n",
      "Iteration 20 out of 120 with Number of features = 2500 | Maximum depth = 4\n",
      "Iteration 20 was 0.17975401878356934 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2500) is : 45.21 %\n",
      "Iteration 21 out of 120 with Number of features = 2500 | Maximum depth = 6\n",
      "Iteration 21 was 0.23013019561767578 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2500) is : 46.6 %\n",
      "Iteration 22 out of 120 with Number of features = 2500 | Maximum depth = 8\n",
      "Iteration 22 was 0.27809691429138184 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2500) is : 48.54 %\n",
      "Iteration 23 out of 120 with Number of features = 2500 | Maximum depth = 10\n",
      "Iteration 23 was 0.325908899307251 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2500) is : 48.96 %\n",
      "Iteration 24 out of 120 with Number of features = 2500 | Maximum depth = 12\n",
      "Iteration 24 was 0.3576047420501709 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=3000) is : 37.27 %\n",
      "Iteration 25 out of 120 with Number of features = 3000 | Maximum depth = 2\n",
      "Iteration 25 was 0.11165094375610352 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=3000) is : 45.62 %\n",
      "Iteration 26 out of 120 with Number of features = 3000 | Maximum depth = 4\n",
      "Iteration 26 was 0.17714929580688477 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=3000) is : 45.76 %\n",
      "Iteration 27 out of 120 with Number of features = 3000 | Maximum depth = 6\n",
      "Iteration 27 was 0.22326111793518066 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=3000) is : 46.46 %\n",
      "Iteration 28 out of 120 with Number of features = 3000 | Maximum depth = 8\n",
      "Iteration 28 was 0.28272509574890137 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=3000) is : 49.37 %\n",
      "Iteration 29 out of 120 with Number of features = 3000 | Maximum depth = 10\n",
      "Iteration 29 was 0.31287193298339844 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=3000) is : 49.09 %\n",
      "Iteration 30 out of 120 with Number of features = 3000 | Maximum depth = 12\n",
      "Iteration 30 was 0.35703182220458984 s long\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on Decision Tree Classifier with no TF-IDF and no tokenizer\n",
    "n_features, max_depth = np.linspace(1000, max_features, 5, dtype = int), [2,4,6,8,10,12]\n",
    "accuracies_DT = {}\n",
    "executions_DT = {}\n",
    "count = 1\n",
    "for n in n_features:\n",
    "    for depth in max_depth:\n",
    "        classifier, processor = DecisionTreeClassifier(max_features = n, max_depth = depth), TextProcessor(True, True, False, None, False, 2500)\n",
    "        start = time.time()\n",
    "        label = f'Number of features = {n} | Maximum depth = {depth}'\n",
    "        X = processor.trainX(train_corpus)\n",
    "        validation = CrossValidation(10)\n",
    "        accuracies_DT[label] = validation.validate(classifier, X, Y_train, False, unique_categories, False)\n",
    "        end = time.time()\n",
    "        step = end - start\n",
    "        executions_DT[label] = step\n",
    "        print(f'Iteration {count} out of 120 with Number of features = {n} | Maximum depth = {depth}')\n",
    "        print(f'Iteration {count} was {step} s long')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5257629107981221"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_DT = max(accuracies_DT, key = accuracies_DT.get)\n",
    "accuracies_DT[u_DT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1000) is : 41.73 %\n",
      "Iteration 1 out of 30 with Number of features = 1000 | Maximum depth = 2\n",
      "Iteration 1 was 6.030891180038452 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1000) is : 46.32 %\n",
      "Iteration 2 out of 30 with Number of features = 1000 | Maximum depth = 4\n",
      "Iteration 2 was 4.902533054351807 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1000) is : 51.05 %\n",
      "Iteration 3 out of 30 with Number of features = 1000 | Maximum depth = 6\n",
      "Iteration 3 was 5.410880088806152 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1000) is : 55.36 %\n",
      "Iteration 4 out of 30 with Number of features = 1000 | Maximum depth = 8\n",
      "Iteration 4 was 5.074504852294922 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1000) is : 56.61 %\n",
      "Iteration 5 out of 30 with Number of features = 1000 | Maximum depth = 10\n",
      "Iteration 5 was 5.202574253082275 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1000) is : 56.47 %\n",
      "Iteration 6 out of 30 with Number of features = 1000 | Maximum depth = 12\n",
      "Iteration 6 was 5.198751926422119 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1500) is : 41.73 %\n",
      "Iteration 7 out of 30 with Number of features = 1500 | Maximum depth = 2\n",
      "Iteration 7 was 5.094727993011475 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1500) is : 47.16 %\n",
      "Iteration 8 out of 30 with Number of features = 1500 | Maximum depth = 4\n",
      "Iteration 8 was 5.0726540088653564 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1500) is : 50.91 %\n",
      "Iteration 9 out of 30 with Number of features = 1500 | Maximum depth = 6\n",
      "Iteration 9 was 5.110316038131714 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1500) is : 55.77 %\n",
      "Iteration 10 out of 30 with Number of features = 1500 | Maximum depth = 8\n",
      "Iteration 10 was 5.206772089004517 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1500) is : 54.66 %\n",
      "Iteration 11 out of 30 with Number of features = 1500 | Maximum depth = 10\n",
      "Iteration 11 was 5.369570016860962 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1500) is : 56.47 %\n",
      "Iteration 12 out of 30 with Number of features = 1500 | Maximum depth = 12\n",
      "Iteration 12 was 5.460327863693237 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2000) is : 41.45 %\n",
      "Iteration 13 out of 30 with Number of features = 2000 | Maximum depth = 2\n",
      "Iteration 13 was 5.020183086395264 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2000) is : 46.46 %\n",
      "Iteration 14 out of 30 with Number of features = 2000 | Maximum depth = 4\n",
      "Iteration 14 was 5.070353984832764 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2000) is : 50.21 %\n",
      "Iteration 15 out of 30 with Number of features = 2000 | Maximum depth = 6\n",
      "Iteration 15 was 5.165337085723877 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2000) is : 55.91 %\n",
      "Iteration 16 out of 30 with Number of features = 2000 | Maximum depth = 8\n",
      "Iteration 16 was 5.200932025909424 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2000) is : 54.52 %\n",
      "Iteration 17 out of 30 with Number of features = 2000 | Maximum depth = 10\n",
      "Iteration 17 was 5.234000205993652 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2000) is : 56.46 %\n",
      "Iteration 18 out of 30 with Number of features = 2000 | Maximum depth = 12\n",
      "Iteration 18 was 5.920997858047485 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2500) is : 42.01 %\n",
      "Iteration 19 out of 30 with Number of features = 2500 | Maximum depth = 2\n",
      "Iteration 19 was 5.2561211585998535 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2500) is : 46.6 %\n",
      "Iteration 20 out of 30 with Number of features = 2500 | Maximum depth = 4\n",
      "Iteration 20 was 5.296519994735718 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2500) is : 50.49 %\n",
      "Iteration 21 out of 30 with Number of features = 2500 | Maximum depth = 6\n",
      "Iteration 21 was 5.289938926696777 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2500) is : 55.63 %\n",
      "Iteration 22 out of 30 with Number of features = 2500 | Maximum depth = 8\n",
      "Iteration 22 was 5.2285120487213135 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2500) is : 54.24 %\n",
      "Iteration 23 out of 30 with Number of features = 2500 | Maximum depth = 10\n",
      "Iteration 23 was 5.36402702331543 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2500) is : 56.47 %\n",
      "Iteration 24 out of 30 with Number of features = 2500 | Maximum depth = 12\n",
      "Iteration 24 was 5.296278953552246 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=3000) is : 42.01 %\n",
      "Iteration 25 out of 30 with Number of features = 3000 | Maximum depth = 2\n",
      "Iteration 25 was 5.098299026489258 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=3000) is : 46.18 %\n",
      "Iteration 26 out of 30 with Number of features = 3000 | Maximum depth = 4\n",
      "Iteration 26 was 5.1980650424957275 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=3000) is : 50.77 %\n",
      "Iteration 27 out of 30 with Number of features = 3000 | Maximum depth = 6\n",
      "Iteration 27 was 5.171403169631958 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=3000) is : 55.36 %\n",
      "Iteration 28 out of 30 with Number of features = 3000 | Maximum depth = 8\n",
      "Iteration 28 was 5.242625951766968 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=3000) is : 54.38 %\n",
      "Iteration 29 out of 30 with Number of features = 3000 | Maximum depth = 10\n",
      "Iteration 29 was 5.2567408084869385 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=3000) is : 56.74 %\n",
      "Iteration 30 out of 30 with Number of features = 3000 | Maximum depth = 12\n",
      "Iteration 30 was 5.4533209800720215 s long\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on Decision Tree Classifier with TF-IDF and Lemma tokenizer\n",
    "n_features, max_depth = np.linspace(1000, max_features, 5, dtype = int), [2,4,6,8,10,12]\n",
    "accuracies_DT2 = {}\n",
    "executions_DT2 = {}\n",
    "token = LemmaTokenizer()\n",
    "count = 1\n",
    "for n in n_features:\n",
    "    for depth in max_depth:\n",
    "        classifier, processor = DecisionTreeClassifier(max_features = n, max_depth = depth), TextProcessor(True, True, True, token, False, n)\n",
    "        start = time.time()\n",
    "        label = f'Number of features = {n} | Maximum depth = {depth}'\n",
    "        X = processor.trainX(train_corpus)\n",
    "        validation = CrossValidation(10)\n",
    "        accuracies_DT2[label] = validation.validate(classifier, X, Y_train, False, unique_categories, False)\n",
    "        end = time.time()\n",
    "        step = end - start\n",
    "        executions_DT2[label] = step\n",
    "        print(f'Iteration {count} out of 30 with Number of features = {n} | Maximum depth = {depth}')\n",
    "        print(f'Iteration {count} was {step} s long')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5674491392801253"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the maximum accuracy obtained\n",
    "u_DT2= max(accuracies_DT2, key = accuracies_DT2.get)\n",
    "accuracies_DT2[u_DT2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of features = 1000 | Maximum depth = 2': 6.030891180038452,\n",
       " 'Number of features = 1000 | Maximum depth = 4': 4.902533054351807,\n",
       " 'Number of features = 1000 | Maximum depth = 6': 5.410880088806152,\n",
       " 'Number of features = 1000 | Maximum depth = 8': 5.074504852294922,\n",
       " 'Number of features = 1000 | Maximum depth = 10': 5.202574253082275,\n",
       " 'Number of features = 1000 | Maximum depth = 12': 5.198751926422119,\n",
       " 'Number of features = 1500 | Maximum depth = 2': 5.094727993011475,\n",
       " 'Number of features = 1500 | Maximum depth = 4': 5.0726540088653564,\n",
       " 'Number of features = 1500 | Maximum depth = 6': 5.110316038131714,\n",
       " 'Number of features = 1500 | Maximum depth = 8': 5.206772089004517,\n",
       " 'Number of features = 1500 | Maximum depth = 10': 5.369570016860962,\n",
       " 'Number of features = 1500 | Maximum depth = 12': 5.460327863693237,\n",
       " 'Number of features = 2000 | Maximum depth = 2': 5.020183086395264,\n",
       " 'Number of features = 2000 | Maximum depth = 4': 5.070353984832764,\n",
       " 'Number of features = 2000 | Maximum depth = 6': 5.165337085723877,\n",
       " 'Number of features = 2000 | Maximum depth = 8': 5.200932025909424,\n",
       " 'Number of features = 2000 | Maximum depth = 10': 5.234000205993652,\n",
       " 'Number of features = 2000 | Maximum depth = 12': 5.920997858047485,\n",
       " 'Number of features = 2500 | Maximum depth = 2': 5.2561211585998535,\n",
       " 'Number of features = 2500 | Maximum depth = 4': 5.296519994735718,\n",
       " 'Number of features = 2500 | Maximum depth = 6': 5.289938926696777,\n",
       " 'Number of features = 2500 | Maximum depth = 8': 5.2285120487213135,\n",
       " 'Number of features = 2500 | Maximum depth = 10': 5.36402702331543,\n",
       " 'Number of features = 2500 | Maximum depth = 12': 5.296278953552246,\n",
       " 'Number of features = 3000 | Maximum depth = 2': 5.098299026489258,\n",
       " 'Number of features = 3000 | Maximum depth = 4': 5.1980650424957275,\n",
       " 'Number of features = 3000 | Maximum depth = 6': 5.171403169631958,\n",
       " 'Number of features = 3000 | Maximum depth = 8': 5.242625951766968,\n",
       " 'Number of features = 3000 | Maximum depth = 10': 5.2567408084869385,\n",
       " 'Number of features = 3000 | Maximum depth = 12': 5.4533209800720215}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executions_DT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of features = 3000 | Maximum depth = 12'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_DT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "max_depth = [2, 4, 6, 8, 10, 12]\n",
    "for d in max_depth:\n",
    "    trick = [key for key in executions_DT2.keys() if f'Maximum depth = {d}' in key]\n",
    "    results.append(np.mean([executions_DT2[key] for key in trick]))\n",
    "plt.grid()\n",
    "plt.plot(max_depth, results, color = 'g')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Runtime execution (s)')\n",
    "plt.title('Runtime execution vs max depth for DT optimization')\n",
    "plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1000) is : 37.41 %\n",
      "Iteration 1 out of 30 with Number of features = 1000 | Maximum depth = 2\n",
      "Iteration 1 was 0.1014249324798584 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1000) is : 45.76 %\n",
      "Iteration 2 out of 30 with Number of features = 1000 | Maximum depth = 4\n",
      "Iteration 2 was 0.10767316818237305 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1000) is : 46.04 %\n",
      "Iteration 3 out of 30 with Number of features = 1000 | Maximum depth = 6\n",
      "Iteration 3 was 0.13252997398376465 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1000) is : 46.46 %\n",
      "Iteration 4 out of 30 with Number of features = 1000 | Maximum depth = 8\n",
      "Iteration 4 was 0.16157293319702148 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1000) is : 48.12 %\n",
      "Iteration 5 out of 30 with Number of features = 1000 | Maximum depth = 10\n",
      "Iteration 5 was 0.18688416481018066 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1000) is : 50.21 %\n",
      "Iteration 6 out of 30 with Number of features = 1000 | Maximum depth = 12\n",
      "Iteration 6 was 0.20435190200805664 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=1500) is : 37.41 %\n",
      "Iteration 7 out of 30 with Number of features = 1500 | Maximum depth = 2\n",
      "Iteration 7 was 0.09964585304260254 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=1500) is : 45.49 %\n",
      "Iteration 8 out of 30 with Number of features = 1500 | Maximum depth = 4\n",
      "Iteration 8 was 0.15160584449768066 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=1500) is : 45.9 %\n",
      "Iteration 9 out of 30 with Number of features = 1500 | Maximum depth = 6\n",
      "Iteration 9 was 0.18276095390319824 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=1500) is : 46.04 %\n",
      "Iteration 10 out of 30 with Number of features = 1500 | Maximum depth = 8\n",
      "Iteration 10 was 0.227888822555542 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=1500) is : 47.84 %\n",
      "Iteration 11 out of 30 with Number of features = 1500 | Maximum depth = 10\n",
      "Iteration 11 was 0.24583768844604492 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=1500) is : 49.51 %\n",
      "Iteration 12 out of 30 with Number of features = 1500 | Maximum depth = 12\n",
      "Iteration 12 was 0.28800415992736816 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2000) is : 37.41 %\n",
      "Iteration 13 out of 30 with Number of features = 2000 | Maximum depth = 2\n",
      "Iteration 13 was 0.11817026138305664 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2000) is : 45.62 %\n",
      "Iteration 14 out of 30 with Number of features = 2000 | Maximum depth = 4\n",
      "Iteration 14 was 0.17282509803771973 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2000) is : 44.93 %\n",
      "Iteration 15 out of 30 with Number of features = 2000 | Maximum depth = 6\n",
      "Iteration 15 was 0.21791887283325195 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2000) is : 45.62 %\n",
      "Iteration 16 out of 30 with Number of features = 2000 | Maximum depth = 8\n",
      "Iteration 16 was 0.27601194381713867 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2000) is : 48.12 %\n",
      "Iteration 17 out of 30 with Number of features = 2000 | Maximum depth = 10\n",
      "Iteration 17 was 0.30732178688049316 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2000) is : 49.51 %\n",
      "Iteration 18 out of 30 with Number of features = 2000 | Maximum depth = 12\n",
      "Iteration 18 was 0.36542677879333496 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=2500) is : 37.27 %\n",
      "Iteration 19 out of 30 with Number of features = 2500 | Maximum depth = 2\n",
      "Iteration 19 was 0.13244390487670898 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=2500) is : 45.62 %\n",
      "Iteration 20 out of 30 with Number of features = 2500 | Maximum depth = 4\n",
      "Iteration 20 was 0.22590899467468262 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=2500) is : 45.07 %\n",
      "Iteration 21 out of 30 with Number of features = 2500 | Maximum depth = 6\n",
      "Iteration 21 was 0.2819230556488037 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=2500) is : 45.2 %\n",
      "Iteration 22 out of 30 with Number of features = 2500 | Maximum depth = 8\n",
      "Iteration 22 was 0.33096790313720703 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=2500) is : 47.56 %\n",
      "Iteration 23 out of 30 with Number of features = 2500 | Maximum depth = 10\n",
      "Iteration 23 was 0.3630709648132324 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=2500) is : 48.68 %\n",
      "Iteration 24 out of 30 with Number of features = 2500 | Maximum depth = 12\n",
      "Iteration 24 was 0.40288805961608887 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=2, max_features=3000) is : 37.27 %\n",
      "Iteration 25 out of 30 with Number of features = 3000 | Maximum depth = 2\n",
      "Iteration 25 was 0.1507120132446289 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=4, max_features=3000) is : 45.62 %\n",
      "Iteration 26 out of 30 with Number of features = 3000 | Maximum depth = 4\n",
      "Iteration 26 was 0.23174595832824707 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=6, max_features=3000) is : 45.06 %\n",
      "Iteration 27 out of 30 with Number of features = 3000 | Maximum depth = 6\n",
      "Iteration 27 was 0.2997119426727295 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=8, max_features=3000) is : 45.34 %\n",
      "Iteration 28 out of 30 with Number of features = 3000 | Maximum depth = 8\n",
      "Iteration 28 was 0.35810089111328125 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=10, max_features=3000) is : 47.84 %\n",
      "Iteration 29 out of 30 with Number of features = 3000 | Maximum depth = 10\n",
      "Iteration 29 was 0.4167671203613281 s long\n",
      "Averrage accuracy of DecisionTreeClassifier(max_depth=12, max_features=3000) is : 49.37 %\n",
      "Iteration 30 out of 30 with Number of features = 3000 | Maximum depth = 12\n",
      "Iteration 30 was 0.4938368797302246 s long\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on Decision Tree Classifier with TF-IDF and no tokenizer\n",
    "n_features, max_depth = np.linspace(1000, max_features, 5, dtype = int), [2,4,6,8,10,12]\n",
    "accuracies_DT3 = {}\n",
    "executions_DT3 = {}\n",
    "token = None\n",
    "count = 1\n",
    "for n in n_features:\n",
    "    for depth in max_depth:\n",
    "        classifier, processor = DecisionTreeClassifier(max_features = n, max_depth = depth), TextProcessor(True, True, True, token, False, n)\n",
    "        start = time.time()\n",
    "        label = f'Number of features = {n} | Maximum depth = {depth}'\n",
    "        X = processor.trainX(train_corpus)\n",
    "        validation = CrossValidation(10)\n",
    "        accuracies_DT3[label] = validation.validate(classifier, X, Y_train, False, unique_categories, False)\n",
    "        end = time.time()\n",
    "        step = end - start\n",
    "        executions_DT3[label] = step\n",
    "        print(f'Iteration {count} out of 30 with Number of features = {n} | Maximum depth = {depth}')\n",
    "        print(f'Iteration {count} was {step} s long')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5020931142410017"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_DT3= max(accuracies_DT3, key = accuracies_DT3.get)\n",
    "accuracies_DT3[u_DT3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aymenboustani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'textprocessor' from '/Users/aymenboustani/Desktop/McGill/Fall 2023/ECSE 551/textprocessor.py'>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(textprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 63.42 %\n",
      "Iteration 1 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 1 was 27.71610713005066 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.49 %\n",
      "Iteration 2 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 2 was 28.361444234848022 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.22 %\n",
      "Iteration 3 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 3 was 28.131960153579712 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.5 %\n",
      "Iteration 4 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 4 was 27.602159023284912 s long\n",
      "Averrage accuracy of Naive Bayes is : 42.42 %\n",
      "Iteration 5 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 5 was 27.77466130256653 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 6 out of 6 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 6 was 27.57475709915161 s long\n"
     ]
    }
   ],
   "source": [
    "# 10 folds Cross Validation with the best hyperparameters, iterating over N-Grams:\n",
    "smooth = True\n",
    "tfidf = normal = False\n",
    "ngrams = [(x, y) for x, y in product([1,2,3], repeat=2) if x <= y]\n",
    "features, token = 2500, None\n",
    "accuracies_N, count, execution_N = {}, 1, {}\n",
    "for ngram in ngrams:\n",
    "    start = time.time()\n",
    "    label = f'TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {features} | Tokenizer = {token} | Ngrams = {ngram}'\n",
    "    processor = TextProcessor(True, True, tfidf, token, normal, features, ngram)\n",
    "    X = processor.trainX(train_corpus)\n",
    "    model, validation = NaiveBayes(smooth), CrossValidation(10)\n",
    "    accuracies_N[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "    end = time.time()\n",
    "    step = end - start\n",
    "    execution_N[label] = step\n",
    "    print(f'Iteration {count} out of 6 with TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {features} | Tokenizer = {token} | Ngrams = {ngram}')\n",
    "    print(f'Iteration {count} was {step} s long')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 58.27 %\n",
      "Iteration 1 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 1 was 10.865885972976685 s long\n",
      "Averrage accuracy of Naive Bayes is : 57.02 %\n",
      "Iteration 2 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 2 was 11.205652952194214 s long\n",
      "Averrage accuracy of Naive Bayes is : 55.07 %\n",
      "Iteration 3 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 3 was 11.175888061523438 s long\n",
      "Averrage accuracy of Naive Bayes is : 45.2 %\n",
      "Iteration 4 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 4 was 11.407249927520752 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.5 %\n",
      "Iteration 5 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 5 was 11.32511305809021 s long\n",
      "Averrage accuracy of Naive Bayes is : 28.1 %\n",
      "Iteration 6 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 6 was 11.402239084243774 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.49 %\n",
      "Iteration 7 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 7 was 17.16574192047119 s long\n",
      "Averrage accuracy of Naive Bayes is : 58.27 %\n",
      "Iteration 8 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 8 was 16.76959204673767 s long\n",
      "Averrage accuracy of Naive Bayes is : 58.97 %\n",
      "Iteration 9 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 9 was 17.038317918777466 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.92 %\n",
      "Iteration 10 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 10 was 16.75796127319336 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.64 %\n",
      "Iteration 11 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 11 was 16.7564640045166 s long\n",
      "Averrage accuracy of Naive Bayes is : 26.99 %\n",
      "Iteration 12 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 12 was 16.61503505706787 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.17 %\n",
      "Iteration 13 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 13 was 22.364289045333862 s long\n",
      "Averrage accuracy of Naive Bayes is : 59.66 %\n",
      "Iteration 14 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 14 was 22.602091073989868 s long\n",
      "Averrage accuracy of Naive Bayes is : 57.85 %\n",
      "Iteration 15 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 15 was 22.19857692718506 s long\n",
      "Averrage accuracy of Naive Bayes is : 47.84 %\n",
      "Iteration 16 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 16 was 22.43134307861328 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.09 %\n",
      "Iteration 17 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 17 was 22.3993182182312 s long\n",
      "Averrage accuracy of Naive Bayes is : 27.54 %\n",
      "Iteration 18 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 18 was 22.844600915908813 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.42 %\n",
      "Iteration 19 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 19 was 27.96343207359314 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.49 %\n",
      "Iteration 20 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 20 was 27.63085389137268 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.22 %\n",
      "Iteration 21 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 21 was 27.98078966140747 s long\n",
      "Averrage accuracy of Naive Bayes is : 44.5 %\n",
      "Iteration 22 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 22 was 27.616974115371704 s long\n",
      "Averrage accuracy of Naive Bayes is : 42.42 %\n",
      "Iteration 23 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 23 was 27.63795518875122 s long\n",
      "Averrage accuracy of Naive Bayes is : 25.04 %\n",
      "Iteration 24 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 24 was 27.72896981239319 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.15 %\n",
      "Iteration 25 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 25 was 33.62631392478943 s long\n",
      "Averrage accuracy of Naive Bayes is : 60.91 %\n",
      "Iteration 26 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (1, 2)\n",
      "Iteration 26 was 33.876538038253784 s long\n",
      "Averrage accuracy of Naive Bayes is : 59.8 %\n",
      "Iteration 27 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (1, 3)\n",
      "Iteration 27 was 34.13101410865784 s long\n",
      "Averrage accuracy of Naive Bayes is : 45.06 %\n",
      "Iteration 28 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (2, 2)\n",
      "Iteration 28 was 33.47355008125305 s long\n",
      "Averrage accuracy of Naive Bayes is : 42.28 %\n",
      "Iteration 29 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (2, 3)\n",
      "Iteration 29 was 34.062161922454834 s long\n",
      "Averrage accuracy of Naive Bayes is : 24.21 %\n",
      "Iteration 30 out of 30 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None | Ngrams = (3, 3)\n",
      "Iteration 30 was 33.85007286071777 s long\n"
     ]
    }
   ],
   "source": [
    "# 10 folds Cross Validation with the best hyperparameters, iterating over N-Grams and number of features:\n",
    "smooth = True\n",
    "tfidf = normal = False\n",
    "ngrams = [(x, y) for x, y in product([1,2,3], repeat=2) if x <= y]\n",
    "features, token = np.linspace(1000,3000,5,dtype = int), None\n",
    "accuracies_N2, count, execution_N2 = {}, 1, {}\n",
    "for n in features:\n",
    "    for ngram in ngrams:\n",
    "        start = time.time()\n",
    "        label = f'TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {n} | Tokenizer = {token} | Ngrams = {ngram}'\n",
    "        processor = TextProcessor(True, True, tfidf, token, normal, n, ngram)\n",
    "        X = processor.trainX(train_corpus)\n",
    "        model, validation = NaiveBayes(smooth), CrossValidation(10)\n",
    "        accuracies_N2[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "        end = time.time()\n",
    "        step = end - start\n",
    "        execution_N2[label] = step\n",
    "        print(f'Iteration {count} out of 30 with TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {n} | Tokenizer = {token} | Ngrams = {ngram}')\n",
    "        print(f'Iteration {count} was {step} s long')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of Naive Bayes is : 63.42 %\n",
      "Iteration 1 out of 5 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 1 was 27.73598599433899 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.87 %\n",
      "Iteration 2 out of 5 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3125 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 2 was 34.52015995979309 s long\n",
      "Averrage accuracy of Naive Bayes is : 63.15 %\n",
      "Iteration 3 out of 5 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3750 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 3 was 42.23354196548462 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.59 %\n",
      "Iteration 4 out of 5 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 4375 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 4 was 49.51335597038269 s long\n",
      "Averrage accuracy of Naive Bayes is : 62.18 %\n",
      "Iteration 5 out of 5 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 5000 | Tokenizer = None | Ngrams = (1, 1)\n",
      "Iteration 5 was 56.08669996261597 s long\n"
     ]
    }
   ],
   "source": [
    "# 10 folds Cross Validation with iteration beyond 3000 features(no token, normalization, tfidf, ngrams = (1,1))\n",
    "smooth = True\n",
    "tfidf = normal = False\n",
    "ngrams = (1,1)\n",
    "features, token = np.linspace(2500,5000,5,dtype = int), None\n",
    "accuracies_N3, count, execution_N3 = {}, 1, {}\n",
    "for n in features:\n",
    "    start = time.time()\n",
    "    label = f'TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {n} | Tokenizer = {token} | Ngrams = {ngrams}'\n",
    "    processor = TextProcessor(True, True, tfidf, token, normal, n, ngrams)\n",
    "    X = processor.trainX(train_corpus)\n",
    "    model, validation = NaiveBayes(smooth), CrossValidation(10)\n",
    "    accuracies_N3[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "    end = time.time()\n",
    "    step = end - start\n",
    "    execution_N3[label] = step\n",
    "    print(f'Iteration {count} out of 5 with TF - IDF = {tfidf} | Normalization = {normal} | Laplace Smoothing = {smooth} | Number of features = {n} | Tokenizer = {token} | Ngrams = {ngrams}')\n",
    "    print(f'Iteration {count} was {step} s long')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 61.76 %\n",
      "Iteration 1 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 1 was 18.83707308769226 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.86 %\n",
      "Iteration 2 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 2 was 25.305021286010742 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.15 %\n",
      "Iteration 3 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 3 was 23.215051889419556 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.43 %\n",
      "Iteration 4 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 4 was 25.24098300933838 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.95 %\n",
      "Iteration 5 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 5 was 26.016488075256348 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.68 %\n",
      "Iteration 6 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 6 was 23.59811806678772 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.01 %\n",
      "Iteration 7 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 7 was 29.204563856124878 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.48 %\n",
      "Iteration 8 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 8 was 31.24337887763977 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.51 %\n",
      "Iteration 9 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 9 was 25.895270824432373 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.85 %\n",
      "Iteration 10 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 10 was 46.20926594734192 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.34 %\n",
      "Iteration 11 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 11 was 54.62567400932312 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.23 %\n",
      "Iteration 12 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 12 was 59.418282985687256 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.76 %\n",
      "Iteration 13 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 13 was 64.2594838142395 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 67.59 %\n",
      "Iteration 14 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 14 was 59.992876052856445 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.65 %\n",
      "Iteration 15 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 15 was 61.09148979187012 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.03 %\n",
      "Iteration 16 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 16 was 17.952518224716187 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.03 %\n",
      "Iteration 17 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 17 was 24.460514068603516 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.15 %\n",
      "Iteration 18 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 18 was 22.72874402999878 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.85 %\n",
      "Iteration 19 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 19 was 21.184403896331787 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.09 %\n",
      "Iteration 20 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 20 was 25.821383953094482 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.42 %\n",
      "Iteration 21 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 21 was 23.715954303741455 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.26 %\n",
      "Iteration 22 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 22 was 25.24386978149414 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.37 %\n",
      "Iteration 23 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 23 was 29.180658102035522 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.53 %\n",
      "Iteration 24 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 24 was 28.39884638786316 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.09 %\n",
      "Iteration 25 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 25 was 58.25622200965881 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.06 %\n",
      "Iteration 26 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 26 was 62.300007820129395 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.51 %\n",
      "Iteration 27 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 27 was 62.88877892494202 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.07 %\n",
      "Iteration 28 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 28 was 62.865336179733276 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.9 %\n",
      "Iteration 29 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 29 was 68.39543581008911 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.48 %\n",
      "Iteration 30 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 30 was 59.46806502342224 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.01 %\n",
      "Iteration 31 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 31 was 26.096591234207153 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 61.61 %\n",
      "Iteration 32 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 32 was 29.438498973846436 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.56 %\n",
      "Iteration 33 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 33 was 27.09192180633545 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.45 %\n",
      "Iteration 34 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 34 was 37.667428970336914 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.98 %\n",
      "Iteration 35 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 35 was 32.27924299240112 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.12 %\n",
      "Iteration 36 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 36 was 35.87659692764282 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.56 %\n",
      "Iteration 37 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 37 was 36.25053429603577 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.65 %\n",
      "Iteration 38 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 38 was 43.7914092540741 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.25 %\n",
      "Iteration 39 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 39 was 35.20026516914368 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.57 %\n",
      "Iteration 40 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 40 was 53.07198214530945 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.65 %\n",
      "Iteration 41 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 41 was 56.475791215896606 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.67 %\n",
      "Iteration 42 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 42 was 55.68061804771423 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.4 %\n",
      "Iteration 43 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 43 was 50.11837315559387 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.9 %\n",
      "Iteration 44 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 44 was 53.591935873031616 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.95 %\n",
      "Iteration 45 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 45 was 65.18750214576721 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 61.48 %\n",
      "Iteration 46 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 46 was 35.49345397949219 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.73 %\n",
      "Iteration 47 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 47 was 33.8673632144928 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.31 %\n",
      "Iteration 48 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 48 was 29.461579084396362 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 63.14 %\n",
      "Iteration 49 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 49 was 27.044279098510742 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.37 %\n",
      "Iteration 50 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 50 was 36.83073425292969 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 62.87 %\n",
      "Iteration 51 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 51 was 27.59076499938965 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.08 %\n",
      "Iteration 52 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 52 was 28.465506076812744 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.09 %\n",
      "Iteration 53 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 53 was 33.86240887641907 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 64.53 %\n",
      "Iteration 54 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 54 was 31.59457778930664 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.65 %\n",
      "Iteration 55 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 55 was 53.543994665145874 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.37 %\n",
      "Iteration 56 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 56 was 51.88440203666687 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.07 %\n",
      "Iteration 57 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 57 was 55.22791242599487 s long\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.1 %\n",
      "Iteration 58 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 58 was 56.39615321159363 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 66.62 %\n",
      "Iteration 59 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 59 was 60.74161219596863 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree', DecisionTreeClassifier()),\n",
      "                               ('RandomForest', RandomForestClassifier()),\n",
      "                               ('BNB', BernoulliNB()),\n",
      "                               ('LogisticRegression', LogisticRegression()),\n",
      "                               ('SVM', LinearSVC(dual=True)),\n",
      "                               ('MNB', MultinomialNB())]) is : 65.24 %\n",
      "Iteration 60 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 60 was 58.57634091377258 s long\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV using Stacking\n",
    "\n",
    "estimators = [\n",
    "    ('DecisionTree', DecisionTreeClassifier()),\n",
    "    ('RandomForest', RandomForestClassifier()),\n",
    "    ('BNB', BernoulliNB()),\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('SVM', LinearSVC(dual = True)),\n",
    "    ('MNB', MultinomialNB())\n",
    "]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "\n",
    "\n",
    "tfidf = normalization = [True, False]\n",
    "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
    "accuracies_stacking, count, execution_stacking = {}, 1, {}\n",
    "for t in tfidf:\n",
    "    for normal in normalization:\n",
    "        for n in features:\n",
    "            for token in tokens:\n",
    "                start = time.time()\n",
    "                label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = True | Number of features = {n} | Tokenizer = {token}'\n",
    "                processor = TextProcessor(True, True, t, token, normal, n)\n",
    "                X = processor.trainX(train_corpus)\n",
    "                model, validation = classifier, CrossValidation(10)\n",
    "                accuracies_stacking[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "                end = time.time()\n",
    "                step = end - start\n",
    "                execution_stacking[label] = step\n",
    "                print(f'Iteration {count} out of 60 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = True | Number of features = {n} | Tokenizer = {token}')\n",
    "                print(f'Iteration {count} was {step} s long')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies_stacking, key = accuracies_stacking.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 67.61 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 75.0 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 75.0 %\n",
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 56.94 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 69.82 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6981611893583726"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and reducing the amount of estimators\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = 5, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV2 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 70.42 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 70.83 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 56.94 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 75.0 %\n",
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 66.67 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 67.88 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6787558685446009"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  no tokenizer and no normalization\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = 5, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, None, False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV3 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 67.61 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 66.67 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 56.94 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 69.26 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.692605633802817"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and no normalization, without Logistic Regression\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV4 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.97 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 65.28 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 65.28 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 83.33 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 66.67 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 73.61 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 67.86 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6786384976525822"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and no normalization, without Logistic Regression and 10 neighbors for KNN\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV5 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.97 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 83.33 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.72 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 66.2 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6619718309859155"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, with Decision Tree and 10 neighbors for KNN\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV7 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 64.79 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 77.78 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.72 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 70.83 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 56.94 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 64.53 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6453442879499217"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, without KNN\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV8 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 65.03 %\n",
      "Iteration 2 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 60.42 %\n",
      "Iteration 3 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 4 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 65.97 %\n",
      "Iteration 5 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 64.95 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6495143745143745"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, \n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))\n",
    "]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(5)\n",
    "accuracy_StackingV9 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.54 %\n",
      "Iteration 2 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 58.33 %\n",
      "Iteration 3 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 70.14 %\n",
      "Iteration 4 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 66.67 %\n",
      "Iteration 5 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.03 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 63.14 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6314102564102564"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, SVM with Linear kernel\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))\n",
    "]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(5)\n",
    "accuracy_StackingV10 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.15 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 56.94 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.72 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 81.94 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 66.67 %\n",
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 65.08 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6508215962441314"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, without SVM\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))\n",
    "]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV11 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.97 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 65.28 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 77.78 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 70.83 %\n",
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 69.44 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 69.44 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 67.86 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6786384976525822"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and reducing the amount of estimators\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = 5, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV12 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.97 %\n",
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 63.89 %\n",
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 61.11 %\n",
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 83.33 %\n",
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 68.06 %\n",
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 72.22 %\n",
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 62.5 %\n",
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]): Accuracy obtained is 59.72 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=10),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))]) is : 66.2 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6619718309859155"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking with with TF-IDF,  LemmaTokenizer and  no normalization, \n",
    "#without Logistic Regression, without GaussianNB, with Decision Tree and 10 neighbors for KNN\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=10), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV13 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 64.79 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 61.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 83.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 72.22 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 70.83 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 69.4 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6939553990610328"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV14 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.24324409, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.21404677, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_kaggle = pd.read_csv('test.csv', encoding = 'cp1252' )\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X_train = processor.trainX(train_corpus)\n",
    "X_test = processor.test_corpus(test_kaggle['body'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 0, 0, 0, 2, 3, 2, 2, 2, 3, 2, 0, 2, 3, 2, 2, 2, 2, 0,\n",
       "       3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 3,\n",
       "       3, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 3, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 3, 2,\n",
       "       1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 3, 1, 3, 0, 3, 3,\n",
       "       3, 3, 1, 3, 2, 0, 2, 2, 2, 2, 3, 1, 3, 2, 0, 3, 0, 0, 1, 2, 3, 0,\n",
       "       1, 1, 3, 3, 3, 2, 3, 2, 2, 3, 0, 2, 1, 3, 3, 2, 3, 1, 3, 3, 3, 1,\n",
       "       1, 0, 3, 1, 0, 3, 3, 2, 3, 3, 0, 0, 2, 0, 2])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Toronto',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'Paris',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'Paris',\n",
       " 'London',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'Toronto',\n",
       " 'Montreal',\n",
       " 'Montreal',\n",
       " 'London',\n",
       " 'London',\n",
       " 'Toronto',\n",
       " 'London',\n",
       " 'Toronto']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_cities = [unique_categories[l] for l in Y_test]\n",
    "Y_test_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>275</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>Toronto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id subreddit\n",
       "0      0   Toronto\n",
       "1      1   Toronto\n",
       "2      2   Toronto\n",
       "3      3    London\n",
       "4      4    London\n",
       "..   ...       ...\n",
       "274  274    London\n",
       "275  275    London\n",
       "276  276   Toronto\n",
       "277  277    London\n",
       "278  278   Toronto\n",
       "\n",
       "[279 rows x 2 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"id\": [i for i in range(len(Y_test_cities))], \"subreddit\" : Y_test_cities} )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 63.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 67.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 5 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 60.42 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)) is : 64.67 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6467171717171717"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 folds CV on stacking using the best hyperparameters found earlier and decreasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(5)\n",
    "accuracy_StackingV15 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 66.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 81.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=SVC(kernel='linear'),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)) is : 68.29 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6828638497652582"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and decreasing estmator, linear kernel for svm\n",
    "# Bagging SVM for the final estimator,\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV16 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 66.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 61.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 77.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state...\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0)),\n",
      "                               ('QDA',\n",
      "                                BaggingClassifier(estimator=QuadraticDiscriminantAnalysis(),\n",
      "                                                  n_estimators=5,\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     n_estimators=5,\n",
      "                                                     random_state=0)) is : 67.73 %\n",
      "459.1410939693451\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and decreasing estmator, linear kernel for svm\n",
    "# Bagging MultinomialNB for the final estimator,\n",
    "estmator = 5\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('QDA', BaggingClassifier(estimator = QuadraticDiscriminantAnalysis(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV17 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 67.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 61.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 70.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 58.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 59.72 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 66.48 %\n",
      "642.6932291984558\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator, estmator = 15, no tokenizer\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, None, False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV18 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 81.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 67.87 %\n",
      "-598.4875030517578\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV19 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(start - end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 58.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 76.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 70.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 66.62 %\n",
      "599.4684178829193\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator, knn removed and decision tree removed\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV20 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 79.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 69.44 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 67.31 %\n",
      "608.2419703006744\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator, knn removed and decision tree removed\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV21 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 61.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 83.33 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 65.28 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 73.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 70.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 72.22 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 69.12 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6911580594679186"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "accuracy_StackingV22 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "accuracy_StackingV22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 64.79 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 61.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 77.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 68.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 76.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 54.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n",
      "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)) is : 65.65 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6564553990610329"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, StemTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV23 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "accuracy_StackingV23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 63.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 62.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
      "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
      "                                                  random_state=0)),\n",
      "                               ('RandomForest',\n",
      "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
      "                                                  random_state=0)),\n",
      "                               ('LogisticRegression',\n",
      "                                BaggingClassifier(estimator=LogisticRegression(),\n",
      "                                                  random_state=0)),\n",
      "                               ('BGNB',\n",
      "                                BaggingClassifier(estimator=GaussianNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('SVM',\n",
      "                                BaggingClassifier(estimator=SVC(kernel='linear'),\n",
      "                                                  random_state=0)),\n",
      "                               ('MNB',\n",
      "                                BaggingClassifier(estimator=MultinomialNB(),\n",
      "                                                  random_state=0)),\n",
      "                               ('KNN',\n",
      "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
      "                                                  random_state=0))],\n",
      "                   final_estimator=BaggingClassifier(base_estimator=LogisticRegression(),\n",
      "                                                     random_state=0)): Accuracy obtained is 77.78 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[243], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m model, validation \u001b[38;5;241m=\u001b[39m classifier, CrossValidation(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     21\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 22\u001b[0m accuracy_StackingV24 \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(end \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/Desktop/McGill/Fall 2023/ECSE 551/crossvalidationmp2.py:42\u001b[0m, in \u001b[0;36mCrossValidation.validate\u001b[0;34m(self, model, X, Y, status, labels, nested)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m     41\u001b[0m   X_train, Y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(folds[:index] \u001b[38;5;241m+\u001b[39m folds[index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]), np\u001b[38;5;241m.\u001b[39mconcatenate(classes[:index] \u001b[38;5;241m+\u001b[39m classes[index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m---> 42\u001b[0m   \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m   predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     44\u001b[0m   compare \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack((Y_test, predicted), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:658\u001b[0m, in \u001b[0;36mStackingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    657\u001b[0m     y_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:249\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    244\u001b[0m         cv\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState()\n\u001b[1;32m    246\u001b[0m     fit_params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    247\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    267\u001b[0m     meth\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method_, all_estimators)\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1033\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m-> 1033\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1041\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1115\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1116\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m   1117\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[1;32m    330\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    331\u001b[0m     X,\n\u001b[1;32m    332\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m )\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[0;32m--> 473\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    492\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[1;32m    493\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:141\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[1;32m    138\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    140\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:298\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    296\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 298\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    300\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using the best hyperparameters found earlier and increasing estmator, linear kernel for svm\n",
    "# Bagging Logistic Regression for the final estimator\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=bootstrap_value)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, False, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_StackingV24 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 59.8 %\n",
      "Iteration 1 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 1 was 3.2773048877716064 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.35 %\n",
      "Iteration 2 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 2 was 9.42112684249878 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.89 %\n",
      "Iteration 3 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 3 was 5.687483787536621 s long\n",
      "Averrage accuracy of SVC() is : 61.2 %\n",
      "Iteration 4 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 4 was 4.974697113037109 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 5 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 5 was 9.824445009231567 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 62.03 %\n",
      "Iteration 6 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 6 was 7.471684217453003 s long\n",
      "Averrage accuracy of SVC() is : 62.03 %\n",
      "Iteration 7 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 7 was 6.64648699760437 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.47 %\n",
      "Iteration 8 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 8 was 11.639604091644287 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 63.01 %\n",
      "Iteration 9 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 9 was 9.309448957443237 s long\n",
      "Averrage accuracy of SVC() is : 62.45 %\n",
      "Iteration 10 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 10 was 8.344974040985107 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 11 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 11 was 13.595626831054688 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 63.28 %\n",
      "Iteration 12 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 12 was 11.077063083648682 s long\n",
      "Averrage accuracy of SVC() is : 62.45 %\n",
      "Iteration 13 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 13 was 10.223490953445435 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 14 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 14 was 15.882853031158447 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 62.58 %\n",
      "Iteration 15 out of 60 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 15 was 12.852720022201538 s long\n",
      "Averrage accuracy of SVC() is : 59.8 %\n",
      "Iteration 16 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 16 was 3.3591291904449463 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.35 %\n",
      "Iteration 17 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 17 was 8.283304929733276 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.89 %\n",
      "Iteration 18 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 18 was 5.714042663574219 s long\n",
      "Averrage accuracy of SVC() is : 61.2 %\n",
      "Iteration 19 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 19 was 5.214109897613525 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 20 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 20 was 10.027413129806519 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 62.03 %\n",
      "Iteration 21 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 21 was 7.514206886291504 s long\n",
      "Averrage accuracy of SVC() is : 62.03 %\n",
      "Iteration 22 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 22 was 6.957984924316406 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.47 %\n",
      "Iteration 23 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 23 was 11.768628120422363 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 63.01 %\n",
      "Iteration 24 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 24 was 9.149096727371216 s long\n",
      "Averrage accuracy of SVC() is : 62.45 %\n",
      "Iteration 25 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 25 was 8.488956928253174 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 26 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 26 was 13.63046908378601 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 63.28 %\n",
      "Iteration 27 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 27 was 10.979446172714233 s long\n",
      "Averrage accuracy of SVC() is : 62.45 %\n",
      "Iteration 28 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 28 was 10.024297952651978 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 61.75 %\n",
      "Iteration 29 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 29 was 15.117792129516602 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 62.58 %\n",
      "Iteration 30 out of 60 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 30 was 12.435934066772461 s long\n",
      "Averrage accuracy of SVC() is : 58.41 %\n",
      "Iteration 31 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 31 was 3.292479991912842 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.85 %\n",
      "Iteration 32 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 32 was 8.312330961227417 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 59.8 %\n",
      "Iteration 33 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 33 was 5.714092016220093 s long\n",
      "Averrage accuracy of SVC() is : 58.97 %\n",
      "Iteration 34 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 34 was 5.038780927658081 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 58.83 %\n",
      "Iteration 35 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 35 was 9.891573905944824 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.5 %\n",
      "Iteration 36 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 36 was 7.451570987701416 s long\n",
      "Averrage accuracy of SVC() is : 59.66 %\n",
      "Iteration 37 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 37 was 6.660187244415283 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 58.41 %\n",
      "Iteration 38 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 38 was 11.5521559715271 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.78 %\n",
      "Iteration 39 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 39 was 9.33696699142456 s long\n",
      "Averrage accuracy of SVC() is : 60.64 %\n",
      "Iteration 40 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 40 was 8.374099016189575 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 58.41 %\n",
      "Iteration 41 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 41 was 13.210355281829834 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.22 %\n",
      "Iteration 42 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 42 was 10.745359182357788 s long\n",
      "Averrage accuracy of SVC() is : 60.77 %\n",
      "Iteration 43 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 43 was 10.226797103881836 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 58.55 %\n",
      "Iteration 44 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 44 was 15.098945140838623 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 60.22 %\n",
      "Iteration 45 out of 60 with TF - IDF = False | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 45 was 12.484177112579346 s long\n",
      "Averrage accuracy of SVC() is : 55.34 %\n",
      "Iteration 46 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 46 was 3.2975268363952637 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 55.76 %\n",
      "Iteration 47 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 47 was 8.198376178741455 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.57 %\n",
      "Iteration 48 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 48 was 5.700477838516235 s long\n",
      "Averrage accuracy of SVC() is : 55.48 %\n",
      "Iteration 49 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 49 was 4.973536014556885 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 56.46 %\n",
      "Iteration 50 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 50 was 9.888709783554077 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.57 %\n",
      "Iteration 51 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 51 was 7.492666006088257 s long\n",
      "Averrage accuracy of SVC() is : 55.48 %\n",
      "Iteration 52 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 52 was 6.689941883087158 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 56.03 %\n",
      "Iteration 53 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 53 was 11.797585010528564 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.57 %\n",
      "Iteration 54 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 54 was 9.218576908111572 s long\n",
      "Averrage accuracy of SVC() is : 56.46 %\n",
      "Iteration 55 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 55 was 8.543241024017334 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 56.31 %\n",
      "Iteration 56 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 56 was 14.102530002593994 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.43 %\n",
      "Iteration 57 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 57 was 10.980731964111328 s long\n",
      "Averrage accuracy of SVC() is : 56.74 %\n",
      "Iteration 58 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 58 was 10.323768138885498 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 56.17 %\n",
      "Iteration 59 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 59 was 14.968818187713623 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of SVC() is : 57.16 %\n",
      "Iteration 60 out of 60 with TF - IDF = False | Normalization = False | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 60 was 12.451283931732178 s long\n"
     ]
    }
   ],
   "source": [
    "#10 folds CV on stacking using SVM\n",
    "classifier = SVC()\n",
    "\n",
    "\n",
    "tfidf = normalization = [True, False]\n",
    "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
    "accuracies_svm, count, execution_svm = {}, 1, {}\n",
    "for t in tfidf:\n",
    "    for normal in normalization:\n",
    "        for n in features:\n",
    "            for token in tokens:\n",
    "                start = time.time()\n",
    "                label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = True | Number of features = {n} | Tokenizer = {token}'\n",
    "                processor = TextProcessor(True, True, t, token, normal, n)\n",
    "                X = processor.trainX(train_corpus)\n",
    "                model, validation = classifier, CrossValidation(10)\n",
    "                accuracies_svm[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "                end = time.time()\n",
    "                step = end - start\n",
    "                execution_svm[label] = step\n",
    "                print(f'Iteration {count} out of 60 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = True | Number of features = {n} | Tokenizer = {token}')\n",
    "                print(f'Iteration {count} was {step} s long')\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_i = max(accuracies_svm, key = accuracies_svm.get)\n",
    "svm_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Iteration 1):\n",
      "[[134   2  29  15]\n",
      " [ 12 137   5  26]\n",
      " [ 34   0 118  27]\n",
      " [ 23  36  36  85]]\n",
      "Accuracy (Iteration 1): 65.92%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Assuming you have already defined classifier, X, and Y_train\n",
    "estmator = 10\n",
    "seed = 0\n",
    "bootstrap_value = False\n",
    "estimators = [\n",
    "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
    "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
    "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
    "\n",
    "final_estimator = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "\n",
    "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "\n",
    "# Perform cross-validation prediction\n",
    "ypred = cross_val_predict(classifier, X, Y_train, cv=4)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_train, ypred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_train, ypred)\n",
    "\n",
    "# Print and plot the confusion matrix\n",
    "print(f\"Confusion Matrix (Iteration 1):\\n{conf_matrix}\")\n",
    "print(f\"Accuracy (Iteration 1): {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=np.unique(Y_train), yticklabels=np.unique(Y_train))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 57.3 %\n",
      "Iteration 1 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 1 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 58.41 %\n",
      "Iteration 2 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1000 | Tokenizer = None\n",
      "Iteration 2 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 59.52 %\n",
      "Iteration 3 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 3 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 59.8 %\n",
      "Iteration 4 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 4 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 57.72 %\n",
      "Iteration 5 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 5 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 60.08 %\n",
      "Iteration 6 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 6 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 61.75 %\n",
      "Iteration 7 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 7 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 59.52 %\n",
      "Iteration 8 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1500 | Tokenizer = None\n",
      "Iteration 8 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 60.5 %\n",
      "Iteration 9 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 9 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 60.63 %\n",
      "Iteration 10 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 10 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 60.64 %\n",
      "Iteration 11 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 11 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 60.07 %\n",
      "Iteration 12 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 12 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 63.27 %\n",
      "Iteration 13 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 13 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 60.49 %\n",
      "Iteration 14 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2000 | Tokenizer = None\n",
      "Iteration 14 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 61.47 %\n",
      "Iteration 15 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 15 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.6 %\n",
      "Iteration 16 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 16 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 61.62 %\n",
      "Iteration 17 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 17 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'nou', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.88 %\n",
      "Iteration 18 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 18 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 62.45 %\n",
      "Iteration 19 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 19 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.05 %\n",
      "Iteration 20 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2500 | Tokenizer = None\n",
      "Iteration 20 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 63.14 %\n",
      "Iteration 21 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 21 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.6 %\n",
      "Iteration 22 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 22 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 61.47 %\n",
      "Iteration 23 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 23 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.74 %\n",
      "Iteration 24 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 24 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 63.14 %\n",
      "Iteration 25 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 25 was 12.451283931732178 s long\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 62.3 %\n",
      "Iteration 26 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 3000 | Tokenizer = None\n",
      "Iteration 26 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 63.84 %\n",
      "Iteration 27 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 27 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 62.16 %\n",
      "Iteration 28 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
      "Iteration 28 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fu', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), n_estimators=5,\n",
      "                  random_state=0) is : 62.03 %\n",
      "Iteration 29 out of 45 with TF - IDF = True | Normalization = False | Kernel = linear | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 29 was 12.451283931732178 s long\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'aur', 'aurion', 'auron', 'avai', 'avion', 'avon', 'ayon', 'becaus', 'befor', 'could', 'dan', 'doe', 'dure', 'e', 'ell', 'euss', 'eussion', 'eûm', 'fuss', 'fussion', 'fûm', 'ha', 'hi', 'mai', 'might', 'must', 'mêm', 'need', 'notr', 'onc', 'onli', 'ourselv', 'pa', 'ser', 'serion', 'seron', 'sha', 'soi', 'somm', 'soyon', 'themselv', 'thi', 'veri', 'vo', 'votr', 'vou', 'wa', 'whi', 'wo', 'would', 'yourselv', 'éti', 'étion', 'ête'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), n_estimators=5, random_state=0) is : 61.88 %\n",
      "Iteration 30 out of 45 with TF - IDF = True | Normalization = False | Kernel = rbf | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
      "Iteration 30 was 12.451283931732178 s long\n"
     ]
    }
   ],
   "source": [
    "#Bagging SVM\n",
    "kernels = ['linear', 'rbf']\n",
    "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
    "accuracies_svmbag, count, execution_svmbag = {}, 1, {}\n",
    "for n in features:\n",
    "    for token in tokens:\n",
    "        for kernel in kernels:\n",
    "            start = time.time()\n",
    "            label = f'TF - IDF = True | Normalization = False | Kernel = {kernel} | Number of features = {n} | Tokenizer = {token}'\n",
    "            processor = TextProcessor(True, True, True, token, False, n)\n",
    "            X = processor.trainX(train_corpus)\n",
    "            model, validation = BaggingClassifier(estimator= SVC(kernel = kernel), \n",
    "                                   n_estimators=estmator, \n",
    "                                   random_state=seed,\n",
    "                                   bootstrap_features=bootstrap_value), CrossValidation(10)\n",
    "            accuracies_svmbag[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
    "            end = time.time()\n",
    "            execution_svmbag[label] = end - start\n",
    "            print(f'Iteration {count} out of 45 with TF - IDF = True | Normalization = False | Kernel = {kernel} | Number of features = {n} | Tokenizer = {token}')\n",
    "            print(f'Iteration {count} was {step} s long')\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 63.38 %\n",
      "Iteration 2 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 62.5 %\n",
      "Iteration 3 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 58.33 %\n",
      "Iteration 4 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 63.89 %\n",
      "Iteration 5 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 73.61 %\n",
      "Iteration 6 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 59.72 %\n",
      "Iteration 7 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 62.5 %\n",
      "Iteration 8 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 70.83 %\n",
      "Iteration 9 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 63.89 %\n",
      "Iteration 10 of 10 - cross fold on the BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0): Accuracy obtained is 61.11 %\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(kernel='linear'), random_state=0) is : 63.98 %\n",
      "41.32486391067505\n"
     ]
    }
   ],
   "source": [
    "#Bagging SVM with linear kernel\n",
    "classifier = BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_SVMBAG = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 54.93 %\n",
      "Iteration 2 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 65.28 %\n",
      "Iteration 3 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 50.0 %\n",
      "Iteration 4 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 58.33 %\n",
      "Iteration 5 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 76.39 %\n",
      "Iteration 6 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 62.5 %\n",
      "Iteration 7 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 59.72 %\n",
      "Iteration 8 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 69.44 %\n",
      "Iteration 9 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 65.28 %\n",
      "Iteration 10 of 10 - cross fold on the BaggingClassifier(estimator=SVC(), random_state=0): Accuracy obtained is 56.94 %\n",
      "Averrage accuracy of BaggingClassifier(estimator=SVC(), random_state=0) is : 61.88 %\n",
      "45.12190914154053\n"
     ]
    }
   ],
   "source": [
    "#Bagging SVM with rbf kernel\n",
    "classifier = BaggingClassifier(estimator= SVC(kernel = 'rbf'), n_estimators=estmator, random_state=seed,bootstrfeatures=bootstrap_value)\n",
    "processor = TextProcessor(True, True, True, LemmaTokenizer(), False)\n",
    "X = processor.trainX(train_corpus)\n",
    "model, validation = classifier, CrossValidation(10)\n",
    "start = time.time()\n",
    "accuracy_SVMBAG_RBF = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
    "end = time.time()\n",
    "print(end- start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montreal'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_categories[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
