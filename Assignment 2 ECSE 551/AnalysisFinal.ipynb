{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports\n"
      ],
      "metadata": {
        "id": "63uSN74KR2l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install nltk\n",
        "%pip install langdetect\n",
        "%pip install spacy\n",
        "%pip install google-colab\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "!python3 -m spacy download fr_core_news_sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "import string\n",
        "import time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from langdetect import detect\n",
        "from naivebayes import NaiveBayes\n",
        "from textprocessor import TextProcessor\n",
        "from crossvalidationmp2 import CrossValidation\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# %pip install nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from nltk.stem.snowball import FrenchStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#For the off-the-shelf models :\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n"
      ],
      "metadata": {
        "id": "NkJJ6MP4R4WK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9e3eae-8c12-48b6-8667-0f64a946fdd5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.17.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.17.3)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.5.5 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.5.5)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.31.0)\n",
            "Requirement already satisfied: tornado==6.3.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (3.1.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (0.18.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook==6.5.5->google-colab) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (1.23.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker==1.5.2->google-colab) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->google-colab) (2023.7.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.5.5->google-colab) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook==6.5.5->google-colab) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook==6.5.5->google-colab) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.5.5->google-colab) (4.19.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.10)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.17.3->google-colab) (0.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.5.5->google-colab) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.5.5->google-colab) (0.12.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook==6.5.5->google-colab) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook==6.5.5->google-colab) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook==6.5.5->google-colab) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.5.5->google-colab) (2.21)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m2023-11-20 04:10:29.026471: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-20 04:10:29.026609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-20 04:10:29.033461: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-20 04:10:31.009207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-11-20 04:10:51.797680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-20 04:10:51.797747: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-20 04:10:51.799141: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-20 04:10:53.077838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting fr-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.6.0/fr_core_news_sm-3.6.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Analysis\n"
      ],
      "metadata": {
        "id": "zrXCnxBJTD3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We start of by downloading the data from the train.csv and test.csv files\n",
        "train_corpus = pd.read_csv('/content/train.csv', encoding = 'cp1252' ).sample(frac = 1)\n",
        "test_corpus = pd.read_csv('/content/test.csv', encoding = 'cp1252' ).sample(frac = 1)\n",
        "max_features = 3000"
      ],
      "metadata": {
        "id": "r8BxZZ5KTGGi"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus['labels'], unique_categories = pd.factorize(train_corpus['subreddit'])"
      ],
      "metadata": {
        "id": "OoLTAxJcTTCQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify that we only have the wanted categories as categories possible for our subreddits\n",
        "unique_categories"
      ],
      "metadata": {
        "id": "0bSyAlTATYX4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aad5716-bf52-438a-8b1f-cd88fb0aec34"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Montreal', 'Paris', 'London', 'Toronto'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot of distribution of each subreddit within the training data:\n",
        "valueCount= train_corpus['subreddit'].value_counts()\n",
        "sum = valueCount.sum()\n",
        "for key, count in valueCount.items():\n",
        "    probability = count / sum\n",
        "    print(f'Proba of {key} is {probability}')\n",
        "\n",
        "\n",
        "\n",
        "valueCountToPlot = valueCount.iloc[:]\n",
        "\n",
        "print('\\n' \"The value count of the data is given by the following :\"'\\n''\\n',valueCount)\n",
        "\n",
        "valueCountToPlot.plot(kind = 'bar')\n",
        "plt.title('Value counts of the different classes of training data')\n",
        "plt.xlabel('Name of cities of subreddit')\n",
        "plt.ylabel('Number of Occurences')\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "H6qasxXpTYOy",
        "outputId": "3e33155a-42e5-4f55-81b8-7d1d5d337878"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proba of Montreal is 0.25034770514603616\n",
            "Proba of Paris is 0.25034770514603616\n",
            "Proba of London is 0.25034770514603616\n",
            "Proba of Toronto is 0.24895688456189152\n",
            "\n",
            "The value count of the data is given by the following :\n",
            "\n",
            " Montreal    180\n",
            "Paris       180\n",
            "London      180\n",
            "Toronto     179\n",
            "Name: subreddit, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Processing"
      ],
      "metadata": {
        "id": "1v6U7rrpUDSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #We create POS tags so that we can lemmatise every single word with the approoriate POS tag.\n",
        "\n",
        " def get_wordnet_pos(word):\n",
        "      tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "      tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "      return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "metadata": {
        "id": "tCqdRuHlXFe2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We start of by implementing a tokenizer based on lemmatization of the words.\n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.nlp_en = spacy.load('en_core_web_sm')\n",
        "        self.nlp_fr = spacy.load('fr_core_news_sm')\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        return self.lemmatize(doc)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Lemma Tokenizer\"\n",
        "\n",
        "    def detect_language(self, text):\n",
        "        try:\n",
        "            lang = detect(text)\n",
        "            return lang\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def lemmatize(self, text):\n",
        "        lang = self.detect_language(text)\n",
        "        if lang == 'fr':\n",
        "            return [token.lemma_ for token in self.nlp_fr(text) if token.text.isalpha()]\n",
        "        else:\n",
        "            return [self.wnl.lemmatize(t, pos=\"v\") for t in word_tokenize(text) if t.isalpha()]\n",
        "\n",
        "#we use a TF-IDF vectorizer to re-weight the count features into floating point values suitable for usage by a classifier\n",
        "class TFIDFVectorizer:\n",
        "    def __init__(self, documents):\n",
        "        self.documents = documents\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(documents)\n",
        "\n",
        "    def __call__(self, query):\n",
        "        query_tfidf = self.vectorizer.transform([query])\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "        tfidf_scores = []\n",
        "        for col in query_tfidf.nonzero()[1]:\n",
        "            term = feature_names[col]\n",
        "            score = query_tfidf[0, col]\n",
        "            tfidf_scores.append((term, score))\n",
        "        tfidf_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return tfidf_scores\n",
        "\n",
        "#We start of by implementing a tokenizer based on stemming of the words.\n",
        "class StemTokenizer:\n",
        "    def __init__(self):\n",
        "        self.wnl_en = PorterStemmer()\n",
        "        self.wnl_fr = SnowballStemmer('french')\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        return self.stem(doc)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Stemming Tokenizer\"\n",
        "\n",
        "    def detect_language(self, text):\n",
        "        try:\n",
        "            lang = detect(text)\n",
        "            return lang\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def stem(self, text):\n",
        "        lang = self.detect_language(text)\n",
        "        if lang == 'fr':\n",
        "            return [self.wnl_fr.stem(t) for t in word_tokenize(text) if t.isalpha()]\n",
        "        else:\n",
        "            return [self.wnl_en.stem(t) for t in word_tokenize(text) if t.isalpha()]\n",
        "\n",
        "class New_LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "\n",
        "    def __call__(self, doc):\n",
        "        return [self.wnl.lemmatize(t, pos= get_wordnet_pos(t)) for t in word_tokenize(doc) if t.isalpha()]\n"
      ],
      "metadata": {
        "id": "D7rgsW0MUFDh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "french_stop_words = set(stopwords.words('french'))\n",
        "english_stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "combined_stop_words = list(french_stop_words.union(english_stop_words).union(punctuation))\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words = combined_stop_words, tokenizer = LemmaTokenizer(), binary = True, max_features= 3000)\n",
        "X_train = vectorizer.fit_transform(train_corpus.to_numpy().T[0])\n",
        "\n",
        "\n",
        "X_train_vec = X_train.toarray()\n",
        "X_train_vec\n",
        "\n",
        "Y_train = train_corpus['labels'].to_numpy()"
      ],
      "metadata": {
        "id": "-2x-JrEEXCwt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Bayes with 10 fold Cross Validation"
      ],
      "metadata": {
        "id": "PHiT6YcrUQLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 folds Cross Validation:\n",
        "tfidf = normalization = smooth = [True, False]\n",
        "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
        "accuracies_NB, count, execution = {}, 1, {}\n",
        "for t in tfidf:\n",
        "    for normal in normalization:\n",
        "        for s in smooth:\n",
        "            for n in features:\n",
        "                for token in tokens:\n",
        "                    start = time.time()\n",
        "                    label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}'\n",
        "                    processor = TextProcessor(True, True, t, token, normal, n)\n",
        "                    X = processor.trainX(train_corpus)\n",
        "                    model, validation = NaiveBayes(s), CrossValidation(5)\n",
        "                    accuracies_NB[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "                    end = time.time()\n",
        "                    step = end - start\n",
        "                    execution[label] = step\n",
        "                    print(f'Iteration {count} out of 120 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
        "                    print(f'Iteration {count} was {step} s long')\n",
        "                    count += 1"
      ],
      "metadata": {
        "id": "4R7scs1pUTJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_NB = max(accuracies_NB, key = accuracies_NB.get)\n",
        "accuracies_NB[u_NB]"
      ],
      "metadata": {
        "id": "gfF_5JI5UXfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_NB"
      ],
      "metadata": {
        "id": "oY3CD2tHUX2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree Classifier"
      ],
      "metadata": {
        "id": "inSdSkWNUbUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Also using 10 nested fold cross validation on the Decision Tree, with no TF-IDF and no tokenizer\n",
        "\n",
        "\n",
        "n_features, max_depth = np.linspace(1000, max_features, 5, dtype = int), [2,4,6,8,10,12]\n",
        "accuracies_DT = {}\n",
        "executions_DT = {}\n",
        "count = 1\n",
        "for n in n_features:\n",
        "    for depth in max_depth:\n",
        "        classifier, processor = DecisionTreeClassifier(max_features = n, max_depth = depth), TextProcessor(True, True, False, None, False, 2500)\n",
        "        start = time.time()\n",
        "        label = f'Number of features = {n} | Maximum depth = {depth}'\n",
        "        X = processor.trainX(train_corpus)\n",
        "        validation = CrossValidation(10)\n",
        "        accuracies_DT[label] = validation.validate(classifier, X, Y_train, False, unique_categories, False)\n",
        "        end = time.time()\n",
        "        step = end - start\n",
        "        executions_DT[label] = step\n",
        "        print(f'Iteration {count} out of 120 with Number of features = {n} | Maximum depth = {depth}')\n",
        "        print(f'Iteration {count} was {step} s long')\n",
        "        count += 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r8tEGgPDUdlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_DT_1 = max(accuracies_DT, key = accuracies_DT.get)\n",
        "u_DT_1"
      ],
      "metadata": {
        "id": "T7qx735AUxyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 folds CV on Decision Tree Classifier with TF-IDF and Lemma tokenizer\n",
        "n_features, max_depth = np.linspace(1000, max_features, 5, dtype = int), [2,4,6,8,10,12]\n",
        "accuracies_DT_2 = {}\n",
        "executions_DT_2 = {}\n",
        "token = LemmaTokenizer()\n",
        "count = 1\n",
        "for n in n_features:\n",
        "    for depth in max_depth:\n",
        "        classifier, processor = DecisionTreeClassifier(max_features = n, max_depth = depth), TextProcessor(True, True, True, token, False, 2500)\n",
        "        start = time.time()\n",
        "        label = f'Number of features = {n} | Maximum depth = {depth}'\n",
        "        X = processor.trainX(train_corpus)\n",
        "        validation = CrossValidation(10)\n",
        "        accuracies_DT_2[label] = validation.validate(classifier, X, Y_train, False, unique_categories, False)\n",
        "        end = time.time()\n",
        "        step = end - start\n",
        "        executions_DT_2[label] = step\n",
        "        print(f'Iteration {count} out of 120 with Number of features = {n} | Maximum depth = {depth}')\n",
        "        print(f'Iteration {count} was {step} s long')\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "MB2I8BLVU0Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_DT_2 = max(accuracies_DT_2, key = accuracies_DT_2.get)\n",
        "u_DT_2"
      ],
      "metadata": {
        "id": "iCx4KTdtU2pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies_DT[u_DT_2]"
      ],
      "metadata": {
        "id": "RJ2qsJkEU6EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processor = TextProcessor(True, True, True, None, True, 2500)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = DecisionTreeClassifier(max_features = 2500, max_depth = 12), CrossValidation(10)\n",
        "accuracies_max_LR = validation.validate(model, X, Y_train, False, unique_categories, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgoValnphieR",
        "outputId": "6e739dfa-8260-47fb-b2ef-37f0fa6dcb96"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of DecisionTreeClassifier(max_depth=12, max_features=2500) is : 51.39 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "aKbd_mqpVWRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "\n",
        "\n",
        "# 10 folds Cross Validation:\n",
        "tfidf = normalization = smooth = [True, False]\n",
        "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
        "accuracies_LR, count, execution = {}, 1, {}\n",
        "for t in tfidf:\n",
        "    for normal in normalization:\n",
        "        for s in smooth:\n",
        "            for n in features:\n",
        "                for token in tokens:\n",
        "                    start = time.time()\n",
        "                    label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}'\n",
        "                    processor = TextProcessor(True, True, t, token, normal, n)\n",
        "                    X = processor.trainX(train_corpus)\n",
        "                    model, validation = LogisticRegression(), CrossValidation(5)\n",
        "                    accuracies_LR[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "                    end = time.time()\n",
        "                    step = end - start\n",
        "                    execution[label] = step\n",
        "                    print(f'Iteration {count} out of 120 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
        "                    print(f'Iteration {count} was {step} s long')\n",
        "                    count += 1"
      ],
      "metadata": {
        "id": "-2UMDEY1VXqY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "054667d8-4b92-46b9-b397-b9ebf88cfe6b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of LogisticRegression() is : 58.97 %\n",
            "Iteration 1 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
            "Iteration 1 was 2.286015033721924 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.48 %\n",
            "Iteration 2 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 2 was 21.325260877609253 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.33 %\n",
            "Iteration 3 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 3 was 12.161352396011353 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.87 %\n",
            "Iteration 4 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
            "Iteration 4 was 1.6143052577972412 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 5 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 5 was 18.130399703979492 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.59 %\n",
            "Iteration 6 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 6 was 14.799328088760376 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.98 %\n",
            "Iteration 7 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
            "Iteration 7 was 2.167325019836426 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 8 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 8 was 17.970204830169678 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.39 %\n",
            "Iteration 9 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 9 was 15.059707164764404 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.67 %\n",
            "Iteration 10 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
            "Iteration 10 was 4.128264665603638 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 11 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 11 was 19.884608030319214 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.28 %\n",
            "Iteration 12 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 12 was 16.88326406478882 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.67 %\n",
            "Iteration 13 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = None\n",
            "Iteration 13 was 4.647766351699829 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.84 %\n",
            "Iteration 14 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 14 was 20.326881408691406 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.83 %\n",
            "Iteration 15 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = True | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 15 was 17.686293840408325 s long\n",
            "Averrage accuracy of LogisticRegression() is : 58.97 %\n",
            "Iteration 16 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = None\n",
            "Iteration 16 was 1.3316752910614014 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.48 %\n",
            "Iteration 17 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 17 was 17.51360821723938 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.33 %\n",
            "Iteration 18 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 18 was 12.418981790542603 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.87 %\n",
            "Iteration 19 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = None\n",
            "Iteration 19 was 2.8880741596221924 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 20 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 20 was 18.801312685012817 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.59 %\n",
            "Iteration 21 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 21 was 12.059133529663086 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.98 %\n",
            "Iteration 22 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = None\n",
            "Iteration 22 was 2.5979247093200684 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 23 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 23 was 17.96493673324585 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.39 %\n",
            "Iteration 24 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 24 was 15.259050607681274 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.67 %\n",
            "Iteration 25 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = None\n",
            "Iteration 25 was 3.7409603595733643 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 26 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 26 was 20.486324071884155 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.28 %\n",
            "Iteration 27 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 2500 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 27 was 17.86519432067871 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.67 %\n",
            "Iteration 28 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = None\n",
            "Iteration 28 was 5.702832221984863 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.84 %\n",
            "Iteration 29 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 29 was 21.487188816070557 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.83 %\n",
            "Iteration 30 out of 120 with TF - IDF = True | Normalization = True | Laplace Smoothing = False | Number of features = 3000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 30 was 16.0533549785614 s long\n",
            "Averrage accuracy of LogisticRegression() is : 58.97 %\n",
            "Iteration 31 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = None\n",
            "Iteration 31 was 2.134096622467041 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.48 %\n",
            "Iteration 32 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 32 was 16.42159414291382 s long\n",
            "Averrage accuracy of LogisticRegression() is : 61.33 %\n",
            "Iteration 33 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 33 was 14.176829814910889 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.87 %\n",
            "Iteration 34 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = None\n",
            "Iteration 34 was 1.6247320175170898 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 35 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 35 was 17.466560125350952 s long\n",
            "Averrage accuracy of LogisticRegression() is : 62.59 %\n",
            "Iteration 36 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 1500 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 36 was 14.12831711769104 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.98 %\n",
            "Iteration 37 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = None\n",
            "Iteration 37 was 3.0179038047790527 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 38 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 38 was 17.910077571868896 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.39 %\n",
            "Iteration 39 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2000 | Tokenizer = Stemming Tokenizer\n",
            "Iteration 39 was 12.212661504745483 s long\n",
            "Averrage accuracy of LogisticRegression() is : 64.67 %\n",
            "Iteration 40 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = None\n",
            "Iteration 40 was 6.447152614593506 s long\n",
            "Averrage accuracy of LogisticRegression() is : 63.42 %\n",
            "Iteration 41 out of 120 with TF - IDF = True | Normalization = False | Laplace Smoothing = True | Number of features = 2500 | Tokenizer = Lemma Tokenizer\n",
            "Iteration 41 was 20.490575313568115 s long\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b980dcec4f18>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0maccuracies_LR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/textprocessor.py\u001b[0m in \u001b[0;36mtrainX\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m       \u001b[0mXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m#normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         )\n\u001b[0;32m-> 2133\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-70babd35843b>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-70babd35843b>\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwnl_fr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-70babd35843b>\u001b[0m in \u001b[0;36mdetect_language\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langdetect/detector_factory.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mwhich\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhighest\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         '''\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36mget_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlangprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36m_detect_block\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_lang_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONV_THRESHOLD\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langdetect/detector.py\u001b[0m in \u001b[0;36m_normalize_prob\u001b[0;34m(self, prob)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmaxp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mmaxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_LR = max(accuracies_LR, key = accuracies_LR.get)\n",
        "accuracies_LR[u_LR]"
      ],
      "metadata": {
        "id": "kLmor1CYVZwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_LR"
      ],
      "metadata": {
        "id": "mQODEfbjVuf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "processor = TextProcessor(True, True, True, New_LemmaTokenizer(), True, 3500)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = LogisticRegression(), CrossValidation(10)\n",
        "accuracies_max_LR = validation.validate(model, X, Y_train, False, unique_categories, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nuYns83ZHgg",
        "outputId": "f682e783-6b15-486b-bfe3-cae1b53b9e4a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of LogisticRegression() is : 61.97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LDA"
      ],
      "metadata": {
        "id": "odhbou2sVyQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LDA\n",
        "\n",
        "\n",
        "# 10 folds Cross Validation:\n",
        "tfidf = normalization = smooth = [True, False]\n",
        "features, tokens = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()]\n",
        "accuracies_LDA, count, execution = {}, 1, {}\n",
        "for t in tfidf:\n",
        "    for normal in normalization:\n",
        "        for s in smooth:\n",
        "            for n in features:\n",
        "                for token in tokens:\n",
        "                    start = time.time()\n",
        "                    label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}'\n",
        "                    processor = TextProcessor(True, True, t, token, normal, n)\n",
        "                    X = processor.trainX(train_corpus)\n",
        "                    model, validation = LinearDiscriminantAnalysis(), CrossValidation(5)\n",
        "                    accuracies_LDA[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "                    end = time.time()\n",
        "                    step = end - start\n",
        "                    execution[label] = step\n",
        "                    print(f'Iteration {count} out of 120 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
        "                    print(f'Iteration {count} was {step} s long')\n",
        "                    count += 1"
      ],
      "metadata": {
        "id": "kTsJ3FVnVzWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_LDA = max(accuracies_LDA, key = accuracies_LDA.get)\n",
        "accuracies_LDA[u_LDA]"
      ],
      "metadata": {
        "id": "a09nEJS8V_Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_LDA"
      ],
      "metadata": {
        "id": "Pm0-05yIWF0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "processor = TextProcessor(True, True, True, New_LemmaTokenizer(), True, 2000)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = LinearDiscriminantAnalysis(), CrossValidation(10)\n",
        "accuracies_max_KNN = validation.validate(model, X, Y_train, False, unique_categories, True)\n",
        "accuracies_max_KNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN7WMIMYsyN8",
        "outputId": "5b784cc6-9ce9-4e2c-c401-9421e30a7de0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of LinearDiscriminantAnalysis() is : 57.75 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5774647887323944"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN"
      ],
      "metadata": {
        "id": "0hUOLraKWG_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using KNN :\n",
        "\n",
        "\n",
        "# 10 folds Cross Validation:\n",
        "tfidf = normalization = smooth = [True, False]\n",
        "features, tokens,neighbours = np.linspace(1000, 3000, 5, dtype = int), [None, LemmaTokenizer(), StemTokenizer()],[3,5,7,10]\n",
        "accuracies_KNN, count, execution = {}, 1, {}\n",
        "for t in tfidf:\n",
        "    for normal in normalization:\n",
        "        for s in smooth:\n",
        "            for n in features:\n",
        "                for token in tokens:\n",
        "                  for N in neighbours:\n",
        "                    start = time.time()\n",
        "                    label = f'TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token} | Number of neighbours = {N}'\n",
        "                    processor = TextProcessor(True, True, t, token, normal, n)\n",
        "                    X = processor.trainX(train_corpus)\n",
        "                    model, validation = KNeighborsClassifier(n_neighbors = N), CrossValidation(10)\n",
        "                    accuracies_KNN[label] = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "                    end = time.time()\n",
        "                    step = end - start\n",
        "                    execution[label] = step\n",
        "                    print(f'Iteration {count} out of 120 with TF - IDF = {t} | Normalization = {normal} | Laplace Smoothing = {s} | Number of features = {n} | Tokenizer = {token}')\n",
        "                    print(f'Iteration {count} was {step} s long')\n",
        "                    count += 1"
      ],
      "metadata": {
        "id": "zXpLAY13WIVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "u_KNN = max(accuracies_KNN, key = accuracies_KNN.get)\n",
        "accuracies_KNN[u_KNN]"
      ],
      "metadata": {
        "id": "FbWhJEVUWLLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "u_KNN"
      ],
      "metadata": {
        "id": "TQp8YOAbWYyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "processor = TextProcessor(True, True, True, StemTokenizer(), True, 3500)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = KNeighborsClassifier(n_neighbors = 10), CrossValidation(10)\n",
        "accuracies_max_KNN = validation.validate(model, X, Y_train, False, unique_categories, True)\n",
        "accuracies_max_KNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMm5eq4Pshp2",
        "outputId": "1f957bd4-1c2a-4369-eac6-50c6b27149ae"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of KNeighborsClassifier(n_neighbors=10) is : 63.38 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6338028169014085"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stacking and Boosting"
      ],
      "metadata": {
        "id": "GdmjK1MYWcOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacking in addition to independant bagging classifiers. Namely,\n",
        "# a logistic regression, a decision tree, a Gradient Boosting Classifier, a SVC classifier, a GaussionNB() classifier, and a MultinomialNB() classifier.\n",
        "\n",
        "seed = 0\n",
        "estmator = 5\n",
        "bootstrap_value = True\n",
        "level0 = list()\n",
        "level0.append(('B_lr', BaggingClassifier(base_estimator= LogisticRegression(C = 0.075), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "level0.append(('B_tree', BaggingClassifier(base_estimator= DecisionTreeClassifier(max_depth=12,max_features=2500), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "level0.append(('B_knn', BaggingClassifier(base_estimator= GradientBoostingClassifier(n_estimators=500, learning_rate=1.0,max_depth=1, random_state=0), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "level0.append(('B_svm', BaggingClassifier(base_estimator= SVC(kernel='rbf'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "level0.append(('B_naive', BaggingClassifier(base_estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "level0.append(('B_naive2', BaggingClassifier(base_estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)))\n",
        "# define meta learner model\n",
        "level1 = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
        "\n",
        "classifier = StackingClassifier(estimators=level0, final_estimator=level1)\n",
        "\n",
        "processor = TextProcessor(True, True, True, New_LemmaTokenizer(), True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "accuracy_Stacking = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "accuracy_Stacking\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "toy7kHzNWett",
        "outputId": "d5e51a57-a444-41a4-deea-5c6219f5935a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-bb26f5ddcc22>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0maccuracy_Stacking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0maccuracy_Stacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/crossvalidationmp2.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model, X, Y, status, labels, nested)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m           \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[0;32m--> 252\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    254\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         )\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         all_results = Parallel(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrequires_feature_indexing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mestimator_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrequires_feature_indexing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the previous classifier,\n",
        "\n",
        "\n",
        "seed = 0\n",
        "estmator = 5\n",
        "bootstrap_value = True\n",
        "level0 = list()\n",
        "level0.append(('B_lr', LogisticRegression(C = 0.075)))\n",
        "level0.append(('B_tree',DecisionTreeClassifier(max_depth=12,max_features=2500)))\n",
        "level0.append(('B_knn', GradientBoostingClassifier(n_estimators=500, learning_rate=1.0,max_depth=1, random_state=0)))\n",
        "level0.append(('B_svm', SVC(kernel='rbf')))\n",
        "level0.append(('B_naive', GaussianNB()))\n",
        "level0.append(('B_naive2', MultinomialNB()))\n",
        "# define meta learner model\n",
        "level1 = BaggingClassifier(base_estimator= LogisticRegression(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
        "\n",
        "classifier = StackingClassifier(estimators=level0, final_estimator=level1)\n",
        "\n",
        "processor = TextProcessor(True, True, True, New_LemmaTokenizer(), True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "accuracy_Stacking = validation.validate(model, X, Y_train, False, unique_categories, False)\n",
        "accuracy_Stacking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "XGWEHc-do3-B",
        "outputId": "336598f2-4711-4830-f3db-5ae05813b636"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4eeaa634aec5>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0maccuracy_Stacking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0maccuracy_Stacking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/crossvalidationmp2.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, model, X, Y, status, labels, nested)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m           \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mcompare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             )\n\u001b[0;32m--> 252\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    253\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    254\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m     predictions = parallel(\n\u001b[0m\u001b[1;32m    987\u001b[0m         delayed(_fit_and_predict)(\n\u001b[1;32m    988\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing the accuracy of each seperate model currenlty being stacked in the stacking classifier\n",
        "processor = TextProcessor(True, True, True,LemmaTokenizer(), True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "\n",
        "for name, model in level0:\n",
        "    print(f\"Accuracy for {name}: {validation.validate(model, X, Y_train, False, unique_categories, False)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBe2rtznag7q",
        "outputId": "80de64d9-ac62-40dc-f445-8345710ea38a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fu', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=LogisticRegression(C=0.075),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 54.5 %\n",
            "Accuracy for B_lr: 0.5450312989045384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12,\n",
            "                                                        max_features=2500),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 55.63 %\n",
            "Accuracy for B_tree: 0.556338028169014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=10),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 47.29 %\n",
            "Accuracy for B_knn: 0.472887323943662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=SVC(), bootstrap_features=True, n_estimators=5,\n",
            "                  random_state=0) is : 59.66 %\n",
            "Accuracy for B_svm: 0.5965766823161188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=GaussianNB(), bootstrap_features=True,\n",
            "                  n_estimators=5, random_state=0) is : 58.68 %\n",
            "Accuracy for B_naive: 0.5867566510172143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=MultinomialNB(), bootstrap_features=True,\n",
            "                  n_estimators=5, random_state=0) is : 58.54 %\n",
            "Accuracy for B_naive2: 0.5854264475743348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only implementing boosting on the desicion Tree.\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "processor = TextProcessor(True, True, True,LemmaTokenizer(), True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(criterion = \"entropy\"), random_state=0), CrossValidation(10)\n",
        "accuracies_boosting = validation.validate(model, X, Y_train, False, unique_categories, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDxx9vAivo2s",
        "outputId": "57a8618c-cfd4-4625-c612-3e153909bf2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aurion', 'avoir', 'could', 'eussion', 'eûme', 'eûte', 'fussion', 'fûme', 'fûte', 'might', 'must', 'need', 'ourselve', 'sha', 'win', 'wo', 'would', 'yourselve', 'éter', 'étion', 'ête', 'être'] not in stop_words.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                   random_state=0) is : 52.11 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Only implementing boosting on the SVM classifier.\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "processor = TextProcessor(True, True, True,None, True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = BaggingClassifier(base_estimator= SVC(kernel = 'linear'), n_estimators=10, random_state=0), CrossValidation(10)\n",
        "accuracies_boosting = validation.validate(model, X, Y_train, False, unique_categories, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYAXYOLY_ftg",
        "outputId": "a92a6556-bb2f-471f-bf4e-23dd834fb5b9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best accuracy of BaggingClassifier(base_estimator=SVC(kernel='linear'), random_state=0) is : 64.79 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10 folds CV on stacking using the best hyperparameters found earlier and decreasing estmator, linear kernel for svm\n",
        "# Bagging SVM for the final estimator,\n",
        "estmator = 5\n",
        "seed = 0\n",
        "bootstrap_value = False\n",
        "estimators = [\n",
        "    ('DecisionTree', BaggingClassifier(estimator= DecisionTreeClassifier(criterion = 'entropy'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
        "    ('RandomForest', BaggingClassifier(estimator= RandomForestClassifier(n_estimators=500, random_state=0), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
        "    ('LogisticRegression', BaggingClassifier(estimator = LogisticRegression(), n_estimators = estmator, random_state = 0,bootstrap_features=False)),\n",
        "    ('SVM', BaggingClassifier(estimator= SVC(kernel = 'linear'), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
        "    ('BGNB', BaggingClassifier(estimator= GaussianNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
        "    ('MNB', BaggingClassifier(estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)),\n",
        "    ('KNN', BaggingClassifier(estimator= KNeighborsClassifier(n_neighbors=5), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value))]\n",
        "\n",
        "final_estimator = BaggingClassifier(base_estimator= MultinomialNB(), n_estimators=estmator, random_state=seed,bootstrap_features=bootstrap_value)\n",
        "\n",
        "classifier = StackingClassifier(estimators = estimators, final_estimator = final_estimator)\n",
        "\n",
        "\n",
        "processor = TextProcessor(True, False, True, LemmaTokenizer(), False)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "accuracy_StackingV16 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
        "accuracy_StackingV16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK8eBlC1yfSR",
        "outputId": "46623511-91d2-4c96-ae6b-6506e80130ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 61.97 %\n",
            "Iteration 2 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 66.67 %\n",
            "Iteration 3 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 65.28 %\n",
            "Iteration 4 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 75.0 %\n",
            "Iteration 5 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 56.94 %\n",
            "Iteration 6 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 65.28 %\n",
            "Iteration 7 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 66.67 %\n",
            "Iteration 8 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 59.72 %\n",
            "Iteration 9 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 68.06 %\n",
            "Iteration 10 of 10 - cross fold on the StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)): Accuracy obtained is 69.44 %\n",
            "Averrage accuracy of StackingClassifier(estimators=[('DecisionTree',\n",
            "                                BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy'),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('RandomForest',\n",
            "                                BaggingClassifier(estimator=RandomForestClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('LogisticRegression',\n",
            "                                BaggingClassifier(estimator=LogisticRegression(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state...\n",
            "                               ('BGNB',\n",
            "                                BaggingClassifier(estimator=GaussianNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('MNB',\n",
            "                                BaggingClassifier(estimator=MultinomialNB(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0)),\n",
            "                               ('KNN',\n",
            "                                BaggingClassifier(estimator=KNeighborsClassifier(),\n",
            "                                                  n_estimators=5,\n",
            "                                                  random_state=0))],\n",
            "                   final_estimator=BaggingClassifier(base_estimator=MultinomialNB(),\n",
            "                                                     n_estimators=5,\n",
            "                                                     random_state=0)) is : 65.5 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6550273865414711"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing the accuracy of each model (seperatly) currently forming the stacking classifier.\n",
        "processor = TextProcessor(True, False, True,LemmaTokenizer(), True)\n",
        "X = processor.trainX(train_corpus)\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "\n",
        "for name, model in level0:\n",
        "    print(f\"Accuracy for {name}: {validation.validate(model, X, Y_train, False, unique_categories, False)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtDi08w_Ol-z",
        "outputId": "44914820-1530-4c30-d68e-26038ef05fbf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averrage accuracy of BaggingClassifier(base_estimator=LogisticRegression(C=0.075),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 52.3 %\n",
            "Accuracy for B_lr: 0.5230046948356807\n",
            "Averrage accuracy of BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=12,\n",
            "                                                        max_features=2500),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 59.12 %\n",
            "Accuracy for B_tree: 0.5911580594679186\n",
            "Averrage accuracy of BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=10),\n",
            "                  bootstrap_features=True, n_estimators=5, random_state=0) is : 46.32 %\n",
            "Accuracy for B_knn: 0.4632042253521127\n",
            "Averrage accuracy of BaggingClassifier(base_estimator=SVC(), bootstrap_features=True, n_estimators=5,\n",
            "                  random_state=0) is : 59.94 %\n",
            "Accuracy for B_svm: 0.5993935837245696\n",
            "Averrage accuracy of BaggingClassifier(base_estimator=GaussianNB(), bootstrap_features=True,\n",
            "                  n_estimators=5, random_state=0) is : 59.39 %\n",
            "Accuracy for B_naive: 0.5939358372456963\n",
            "Averrage accuracy of BaggingClassifier(base_estimator=MultinomialNB(), bootstrap_features=True,\n",
            "                  n_estimators=5, random_state=0) is : 54.8 %\n",
            "Accuracy for B_naive2: 0.5480242566510172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We have also created a confusion matrix based on the previous iteration to understand which classes were we predicting correctly, and which ones we were not.\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "ypred = cross_val_predict(classifier, X, Y_train, cv=4)\n",
        "\n",
        "conf_matrix = confusion_matrix(Y_train, ypred)\n",
        "accuracy = accuracy_score(Y_train, ypred)\n",
        "\n",
        "print(f\"Confusion Matrix (Iteration {1}):\\n{conf_matrix}\")\n",
        "print(f\"Accuracy (Iteration {1}): {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjmIBZ7s5JYn",
        "outputId": "b15e30c7-ab68-490a-8285-78cf714705c8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Iteration 1):\n",
            "[[131   8  25  16]\n",
            " [  0 143   7  29]\n",
            " [ 46  48  56  30]\n",
            " [  0  43   6 131]]\n",
            "Accuracy (Iteration 1): 64.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "\n",
        "processor = TextProcessor(True, False, True, LemmaTokenizer(), False)\n",
        "X = processor.trainX(train_corpus)\n",
        "\n",
        "\n",
        "classifier = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0,max_depth=1, random_state=0)\n",
        "\n",
        "\n",
        "model, validation = classifier, CrossValidation(10)\n",
        "accuracy_StackingV16 = validation.validate(model, X, Y_train, True, unique_categories, False)\n",
        "accuracy_StackingV16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMwtEjTgOrMX",
        "outputId": "112019c6-c668-4c14-dd89-4a53da9a8a2d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 64.79 %\n",
            "Iteration 2 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 65.28 %\n",
            "Iteration 3 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 56.94 %\n",
            "Iteration 4 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 61.11 %\n",
            "Iteration 5 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 54.17 %\n",
            "Iteration 6 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 69.44 %\n",
            "Iteration 7 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 54.17 %\n",
            "Iteration 8 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 63.89 %\n",
            "Iteration 9 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 63.89 %\n",
            "Iteration 10 of 10 - cross fold on the GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0): Accuracy obtained is 66.67 %\n",
            "Averrage accuracy of GradientBoostingClassifier(learning_rate=1.0, max_depth=1, n_estimators=500,\n",
            "                           random_state=0) is : 62.03 %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6203442879499218"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1s6FQ-_cjCkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}